import os
# Fix for MPS 'aten::isin' error: Enable fallback to CPU for unsupported ops
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
# Suppress huggingface/tokenizers parallelism warning
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import uvicorn
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import HTMLResponse, Response
from transformers import AutoProcessor, AutoModelForCausalLM
from PIL import Image
import io
import socket
import qrcode
import sys
import torch
import pathlib
import pathlib
import time
import warnings # Added for warning suppression

# Filter out specific library warnings to keep console clean for students
warnings.filterwarnings("ignore", message=".*To copy construct from a tensor.*")
warnings.filterwarnings("ignore", category=UserWarning, module="transformers")

# 1. åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(title="Lesson 25 Vision Demo (Florence-2)")

# Mock flash_attn for Mac compatibility
from unittest.mock import MagicMock
sys.modules["flash_attn"] = MagicMock()
sys.modules["flash_attn"].__spec__ = MagicMock()

# Helper: Get Local IP
def get_local_ip():
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except:
        return "127.0.0.1"

# 2. é¢„åŠ è½½æ¨¡å‹ (ä½¿ç”¨ Microsoft Florence-2-base)
# ä¼˜å…ˆæ£€æŸ¥æœ¬åœ°æ¨¡å‹
local_model_path = "./models/florence-2-base"
if os.path.exists(local_model_path):
    print(f"ğŸ“‚ å‘ç°æœ¬åœ°æ¨¡å‹ path: {local_model_path}")
    model_id = local_model_path
else:
    print(f"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå‡†å¤‡ä» HuggingFace ä¸‹è½½...")
    model_id = "microsoft/Florence-2-base"
# è‡ªåŠ¨æ£€æµ‹è®¾å¤‡: ä¼˜å…ˆ MPS (Mac), å…¶æ¬¡ CPU
device = "mps" if torch.backends.mps.is_available() else "cpu"
# Florence-2 åœ¨ GPU/MPS ä¸Šé€šå¸¸ä½¿ç”¨ float16ï¼Œä½†åœ¨ CPU ä¸Šä½¿ç”¨ float32
torch_dtype = torch.float16 if device != "cpu" else torch.float32

model = None
processor = None

try:
    print("="*50)
    print(f"ğŸš€ æ­£åœ¨åŠ è½½ Florence-2 æ¨¡å‹...")
    print(f"ğŸ“‚ æ¨¡å‹æ¥æº: {model_id}")
    print(f"ğŸ–¥ï¸  è¿è¡Œè®¾å¤‡: {device.upper()}")
    
    # å¦‚æœå‘ç°æ˜¯æœ¬åœ°è·¯å¾„ï¼Œå¼ºåˆ¶ç¦»çº¿æ¨¡å¼
    local_files_only = False
    if os.path.isdir(model_id):
        print(f"ğŸ”Œ æ£€æµ‹åˆ°æœ¬åœ°è·¯å¾„ï¼Œå¯ç”¨ç¦»çº¿æ¨¡å¼ (local_files_only=True)")
        local_files_only = True
        os.environ["HF_DATASETS_OFFLINE"] = "1"
        os.environ["TRANSFORMERS_OFFLINE"] = "1"
    
    if model_id == "microsoft/Florence-2-base" and not local_files_only:
        print("ç¬¬ä¸€æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ (çº¦ 1.5GB)ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    model = AutoModelForCausalLM.from_pretrained(
        model_id, 
        trust_remote_code=True, 
        torch_dtype=torch_dtype,
        local_files_only=local_files_only
    ).to(device)
    
    processor = AutoProcessor.from_pretrained(
        model_id, 
        trust_remote_code=True,
        local_files_only=local_files_only
    )
    
    print("âœ¨ Florence-2 æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    print("="*50)
except Exception as e:
    import traceback
    print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    print("å¯èƒ½æ˜¯ transformer ç‰ˆæœ¬è¿‡ä½æˆ–ä¾èµ–ç¼ºå¤±ã€‚è¯·å°è¯•è¿è¡Œ: pip install -U transformers timm einops")
    traceback.print_exc()

# 3. æ¨¡å‹é¢„çƒ­ (Warmup) - æ¶ˆé™¤ç¬¬ä¸€æ¬¡è¿è¡Œçš„å¡é¡¿
def warmup_model():
    if not model or not processor: return
    print("ğŸ”¥ æ­£åœ¨é¢„çƒ­æ¨¡å‹... (æ¶ˆé™¤é¦–æ¬¡æ¨ç†å¡é¡¿)")
    try:
        # åˆ›å»ºä¸€ä¸ªæå…¶å¾®å°çš„ Dummy è¾“å…¥
        dummy_img = Image.new('RGB', (64, 64), color='white')
        dummy_prompt = "<CAPTION>"
        inputs = processor(text=dummy_prompt, images=dummy_img, return_tensors="pt").to(device, torch_dtype)
        # å¼ºåˆ¶è¿è¡Œä¸€æ¬¡ç”Ÿæˆ
        model.generate(
            input_ids=inputs["input_ids"],
            pixel_values=inputs["pixel_values"],
            max_new_tokens=5, 
            do_sample=False,
            num_beams=1,
        )
        print("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼")
    except Exception as e:
        print(f"âš ï¸ é¢„çƒ­å¤±è´¥ (ä¸å½±å“ä¸»åŠŸèƒ½): {e}")

# æ‰§è¡Œé¢„çƒ­
warmup_model()

@app.get("/", response_class=HTMLResponse)
def home():
    """Serve the frontend HTML"""
    return pathlib.Path("index.html").read_text(encoding="utf-8")

@app.get("/qrcode")
def get_qr_image():
    """Generate QR Code for the server URL"""
    ip = get_local_ip()
    url = f"http://{ip}:8000"
    print(f"ğŸ“± QR Code URL: {url}")
    
    qr = qrcode.QRCode(box_size=10, border=4)
    qr.add_data(url)
    qr.make(fit=True)
    img = qr.make_image(fill_color="black", back_color="white")
    
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    buf.seek(0)
    return Response(content=buf.getvalue(), media_type="image/png")

@app.post("/upload")
async def upload_image(file: UploadFile = File(...)):
    """
    æ¥æ”¶æ‰‹æœºä¸Šä¼ çš„å›¾ç‰‡ï¼Œå¹¶è¿”å›è¯¦ç»†æè¿° (Detailed Caption)
    """
    global model, processor
    
    if not model or not processor:
        return {"error": "Model not loaded. Check server logs."}

    try:
        # è¯»å–å›¾ç‰‡æ•°æ®
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # æ„é€ æç¤ºè¯ task
        prompt = "<MORE_DETAILED_CAPTION>"
        
        # æ‰“å°æ—¥å¿—åˆ°æ§åˆ¶å°
        print(f"\nğŸ“¸ æ”¶åˆ°å›¾ç‰‡: {file.filename}")
        
        # è®¡æ—¶å¼€å§‹
        start_time = time.time()
        
        # é¢„å¤„ç†è¾“å…¥
        inputs = processor(text=prompt, images=image, return_tensors="pt").to(device, torch_dtype)

        # ç”Ÿæˆæè¿°
        generated_ids = model.generate(
            input_ids=inputs["input_ids"],
            pixel_values=inputs["pixel_values"],
            max_new_tokens=1024,
            do_sample=False,
            num_beams=3,
        )
        
        # è§£ç è¾“å‡º
        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]
        
        # åå¤„ç† (Florence-2 ç‰¹æœ‰)
        parsed_answer = processor.post_process_generation(
            generated_text, 
            task=prompt, 
            image_size=(image.width, image.height)
        )
        
        # è®¡æ—¶ç»“æŸ
        end_time = time.time()
        cost_time = round(end_time - start_time, 2)
        
        # è·å–æœ€ç»ˆæ–‡æœ¬
        caption = parsed_answer[prompt]
        
        # æ‰“å°æ—¥å¿—åˆ°æ§åˆ¶å°
        print(f"â±ï¸ æ¨ç†è€—æ—¶: {cost_time}s")
        print(f"ğŸ¤– Florence-2 æè¿°:\n{caption}")
        
        return {
            "label": caption,
            "cost_time": cost_time
        }
    except Exception as e:
        import traceback
        print(f"âŒ å¤„ç†å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        return {"error": str(e)}

def get_local_ip():
    """è·å–æœ¬æœºå±€åŸŸç½‘IP"""
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except:
        return "127.0.0.1"

def print_qr_code(url):
    """åœ¨ç»ˆç«¯æ‰“å°äºŒç»´ç """
    try:
        qr = qrcode.QRCode()
        qr.add_data(url)
        qr.print_ascii(invert=True)
        print(f"\nğŸ“± æ‰‹æœºæ‰«ç ä½“éªŒ: {url}")
    except Exception:
        print(f"\nâš ï¸ æ— æ³•ç”ŸæˆäºŒç»´ç ï¼Œè¯·æ‰‹åŠ¨è®¿é—®: {url}")

if __name__ == "__main__":
    ip = get_local_ip()
    port = 8000
    url = f"http://{ip}:{port}/docs"
    
    print("\n" + "="*50)
    print(f"ğŸš€ æœåŠ¡å¯åŠ¨ä¸­...")
    print(f"Running on: {url}")
    print("="*50)
    
    # æ‰“å°äºŒç»´ç ä¾›æ‰«æ
    print_qr_code(url)
    
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    
    uvicorn.run(app, host="0.0.0.0", port=port)
