{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# æ¨¡å—ä¸ƒï¼šAI åº”ç”¨å®éªŒæ‰‹å†Œ\n",
                "\n",
                "æœ¬ç¬”è®°æœ¬åˆ›å»ºäº†ä¸€ä¸ªå®Œæ•´çš„ç¯å¢ƒï¼Œç”¨äºè¿è¡Œä½¿ç”¨ **Microsoft Florence-2-base** æ¨¡å‹çš„ AI è§†è§‰æ¼”ç¤ºã€‚\n",
                "\n",
                "## æ­¥éª¤ 0ï¼šå®‰è£…ä¾èµ–\n",
                "æˆ‘ä»¬éœ€è¦å®‰è£…æ‰€éœ€çš„åº“ï¼ŒåŒ…æ‹¬ `transformers`ã€`fastapi`ã€`uvicorn` ä»¥åŠç”¨äºè°ƒç”¨äº‘ç«¯ API çš„ `openai`ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
                        "To disable this warning, you can either:\n",
                        "\t- Avoid using `tokenizers` before the fork if possible\n",
                        "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "zsh:1: no matches found: qrcode[pil]\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "# å®‰è£…ä¾èµ– (å…¼å®¹ Mac/Linux/Windows)\n",
                "# ä½¿ç”¨ transformers==4.51.3 ä»¥ç¡®ä¿ç¨³å®šæ€§ä¸é€Ÿåº¦\n",
                "%pip install transformers==4.51.3 timm einops pillow \"qrcode[pil]\" fastapi uvicorn openai -i https://pypi.tuna.tsinghua.edu.cn/simple"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lesson 25: 3. ä½ çš„ç¬¬ä¸€ä¸ªè§†è§‰è„šæœ¬:çœ‹å›¾è¯´è¯\n",
                "\n",
                "æˆ‘ä»¬å°†åŠ è½½ **Microsoft Florence-2-base** æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ª VLMï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ï¼Œèƒ½å¤Ÿç”Ÿæˆè¯¦ç»†çš„å›¾åƒå­—å¹•ã€‚\n",
                "\n",
                "**Mac ç”¨æˆ·æ³¨æ„ï¼š** æˆ‘ä»¬å¯ç”¨äº† MPS å›é€€æœºåˆ¶ï¼Œå¹¶ä½¿ç”¨ `mock` æŠ€å·§æ¥ç»•è¿‡ `flash_attn` è¦æ±‚ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# 1. å¯ç”¨ MPS å›é€€ (å¿…é¡»åœ¨å¯¼å…¥ torch å‰è®¾ç½®!)\n",
                "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
                "\n",
                "from unittest.mock import MagicMock\n",
                "import torch\n",
                "from transformers import AutoProcessor, AutoModelForCausalLM\n",
                "from PIL import Image\n",
                "\n",
                "# 2. Mock flash_attn æ£€æŸ¥ä»¥å…¼å®¹ Mac\n",
                "sys.modules[\"flash_attn\"] = MagicMock()\n",
                "sys.modules[\"flash_attn\"].__spec__ = MagicMock()\n",
                "\n",
                "# 3. åŠ è½½æ¨¡å‹\n",
                "# ä¼˜å…ˆæ£€æŸ¥æœ¬åœ°æ¨¡å‹ ./models/florence-2-base\n",
                "local_model_path = \"./models/florence-2-base\"\n",
                "if os.path.exists(local_model_path):\n",
                "    model_id = local_model_path\n",
                "    print(f\"ğŸ“‚ ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {model_id}\")\n",
                "else:\n",
                "    model_id = \"microsoft/Florence-2-base\"\n",
                "    print(f\"â˜ï¸ ä½¿ç”¨è¿œç¨‹æ¨¡å‹: {model_id}\")\n",
                "\n",
                "# è‡ªåŠ¨æ£€æµ‹è®¾å¤‡ (Mac ç”¨ MPS, Nvidia ç”¨ CUDA, å¦åˆ™ç”¨ CPU)\n",
                "if torch.backends.mps.is_available():\n",
                "    device = \"mps\"\n",
                "    torch_dtype = torch.float16\n",
                "elif torch.cuda.is_available():\n",
                "    device = \"cuda\"\n",
                "    torch_dtype = torch.float16\n",
                "else:\n",
                "    device = \"cpu\"\n",
                "    torch_dtype = torch.float32\n",
                "\n",
                "print(f\"ä½¿ç”¨è®¾å¤‡: {device.upper()}\")\n",
                "print(\"æ­£åœ¨åŠ è½½æ¨¡å‹... (å¯èƒ½éœ€è¦ä¸€åˆ†é’Ÿ)\")\n",
                "\n",
                "try:\n",
                "    model = AutoModelForCausalLM.from_pretrained(\n",
                "        model_id, \n",
                "        trust_remote_code=True, \n",
                "        torch_dtype=torch_dtype,\n",
                "        local_files_only=True\n",
                "    ).to(device)\n",
                "    \n",
                "    processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
                "    print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!\")\n",
                "except Exception as e:\n",
                "    print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lesson 25: 4. ä»£ç è§£æ (Code Analysis: Inference Test)\n",
                "è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥æµ‹è¯•æ¨¡å‹ã€‚æ‚¨å¯ä»¥åœ¨è¿™é‡Œä¸Šä¼ å›¾åƒè·¯å¾„æˆ– URLã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_image(image_path, task=\"<MORE_DETAILED_CAPTION>\"):\n",
                "    if image_path.startswith(\"http\"):\n",
                "        import requests\n",
                "        image = Image.open(requests.get(image_path, stream=True).raw)\n",
                "    else:\n",
                "        image = Image.open(image_path)\n",
                "    \n",
                "    if image.mode != \"RGB\":\n",
                "        image = image.convert(\"RGB\")\n",
                "\n",
                "    inputs = processor(text=task, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
                "\n",
                "    # ç¬¬ä¸€æ¬¡è¿è¡Œå¯èƒ½ä¼šæ…¢ (Warmup)ï¼Œå› ä¸º MPS éœ€è¦ç¼–è¯‘å›¾\n",
                "    generated_ids = model.generate(\n",
                "        input_ids=inputs[\"input_ids\"],\n",
                "        pixel_values=inputs[\"pixel_values\"],\n",
                "        max_new_tokens=1024,\n",
                "        do_sample=False,\n",
                "        num_beams=3,\n",
                "    )\n",
                "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
                "    parsed_answer = processor.post_process_generation(generated_text, task=task, image_size=(image.width, image.height))\n",
                "    \n",
                "    return parsed_answer[task]\n",
                "\n",
                "# model_warmup() # å¯é€‰: é¢„çƒ­ä¸€æ¬¡\n",
                "\n",
                "# æµ‹è¯• (å¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªå°çš„æµ‹è¯•å›¾ç‰‡)\n",
                "dummy_img_path = \"test_image.jpg\"\n",
                "if not os.path.exists(dummy_img_path):\n",
                "    Image.new('RGB', (100, 100), color = 'red').save(dummy_img_path)\n",
                "    \n",
                "print(\"æ­£åœ¨åˆ†æå›¾ç‰‡...\")\n",
                "try:\n",
                "    print(analyze_image(dummy_img_path))\n",
                "except Exception as e:\n",
                "    print(f\"é”™è¯¯: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lesson 25: 9. æœ€ç»ˆå®éªŒ: ä½ çš„ç¬¬ä¸€ä¸ª AI App\n",
                "æ­å–œï¼æ‚¨å·²ç»åˆ°äº†æœ€åä¸€æ­¥ã€‚æˆ‘ä»¬å°†ç”Ÿæˆå‰ç«¯ä»£ç  (`index.html`) å’Œåç«¯ä»£ç  (`app.py`)ï¼Œç„¶åå¯åŠ¨æœåŠ¡ã€‚\n",
                "\n",
                "### 1. ç”Ÿæˆå‰ç«¯ (index.html)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile index.html\n",
                "<!DOCTYPE html>\n",
                "<html lang=\"zh-CN\">\n",
                "\n",
                "<head>\n",
                "    <meta charset=\"UTF-8\">\n",
                "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\">\n",
                "    <title>AI Vision Demo (Florence-2)</title>\n",
                "    <style>\n",
                "        :root {\n",
                "            --primary-color: #4CAF50;\n",
                "            --bg-color: #1e1e1e;\n",
                "            --card-bg: #252526;\n",
                "            --text-color: #ddd;\n",
                "        }\n",
                "\n",
                "        body {\n",
                "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;\n",
                "            background-color: var(--bg-color);\n",
                "            color: var(--text-color);\n",
                "            display: flex;\n",
                "            flex-direction: column;\n",
                "            align-items: center;\n",
                "            min-height: 100vh;\n",
                "            margin: 0;\n",
                "            padding: 20px;\n",
                "        }\n",
                "\n",
                "        .container {\n",
                "            width: 100%;\n",
                "            max-width: 600px;\n",
                "            display: flex;\n",
                "            flex-direction: column;\n",
                "            gap: 20px;\n",
                "        }\n",
                "\n",
                "        h1 {\n",
                "            text-align: center;\n",
                "            color: var(--primary-color);\n",
                "            margin-bottom: 5px;\n",
                "        }\n",
                "\n",
                "        .subtitle {\n",
                "            text-align: center;\n",
                "            color: #888;\n",
                "            font-size: 0.9em;\n",
                "            margin-bottom: 20px;\n",
                "        }\n",
                "\n",
                "        .card {\n",
                "            background-color: var(--card-bg);\n",
                "            padding: 20px;\n",
                "            border-radius: 12px;\n",
                "            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);\n",
                "        }\n",
                "\n",
                "        /* QR Code Section - Hidden on Mobile */\n",
                "        .qr-section {\n",
                "            text-align: center;\n",
                "            display: flex;\n",
                "            flex-direction: column;\n",
                "            align-items: center;\n",
                "            gap: 10px;\n",
                "        }\n",
                "\n",
                "        .qr-section img {\n",
                "            width: 180px;\n",
                "            height: 180px;\n",
                "            border-radius: 8px;\n",
                "            border: 4px solid white;\n",
                "        }\n",
                "\n",
                "        @media (max-width: 600px) {\n",
                "            .qr-section {\n",
                "                display: none;\n",
                "            }\n",
                "\n",
                "            .mobile-hidden {\n",
                "                display: none;\n",
                "            }\n",
                "        }\n",
                "\n",
                "        @media (min-width: 601px) {\n",
                "            .desktop-hidden {\n",
                "                display: none;\n",
                "            }\n",
                "        }\n",
                "\n",
                "        /* Upload Section */\n",
                "        .upload-area {\n",
                "            border: 2px dashed #444;\n",
                "            border-radius: 8px;\n",
                "            padding: 30px;\n",
                "            text-align: center;\n",
                "            cursor: pointer;\n",
                "            transition: border-color 0.3s;\n",
                "            position: relative;\n",
                "        }\n",
                "\n",
                "        .upload-area:hover {\n",
                "            border-color: var(--primary-color);\n",
                "        }\n",
                "\n",
                "        .upload-area input[type=\"file\"] {\n",
                "            position: absolute;\n",
                "            top: 0;\n",
                "            left: 0;\n",
                "            width: 100%;\n",
                "            height: 100%;\n",
                "            opacity: 0;\n",
                "            cursor: pointer;\n",
                "        }\n",
                "\n",
                "        .icon {\n",
                "            font-size: 48px;\n",
                "            margin-bottom: 10px;\n",
                "            display: block;\n",
                "        }\n",
                "\n",
                "        .btn {\n",
                "            background-color: var(--primary-color);\n",
                "            color: white;\n",
                "            border: none;\n",
                "            padding: 12px 24px;\n",
                "            border-radius: 6px;\n",
                "            font-size: 16px;\n",
                "            font-weight: bold;\n",
                "            cursor: pointer;\n",
                "            width: 100%;\n",
                "            margin-top: 15px;\n",
                "            transition: background-color 0.2s;\n",
                "        }\n",
                "\n",
                "        .btn:disabled {\n",
                "            background-color: #555;\n",
                "            cursor: not-allowed;\n",
                "        }\n",
                "\n",
                "        /* Result Section */\n",
                "        .preview-img {\n",
                "            max-width: 100%;\n",
                "            border-radius: 8px;\n",
                "            margin-bottom: 15px;\n",
                "            border: 1px solid #444;\n",
                "        }\n",
                "\n",
                "        .result-text {\n",
                "            font-size: 1.1em;\n",
                "            line-height: 1.6;\n",
                "            background: #333;\n",
                "            padding: 15px;\n",
                "            border-radius: 8px;\n",
                "            border-left: 4px solid var(--primary-color);\n",
                "        }\n",
                "\n",
                "        .loader {\n",
                "            display: inline-block;\n",
                "            width: 20px;\n",
                "            height: 20px;\n",
                "            border: 3px solid rgba(255, 255, 255, .3);\n",
                "            border-radius: 50%;\n",
                "            border-top-color: #fff;\n",
                "            animation: spin 1s ease-in-out infinite;\n",
                "            margin-right: 10px;\n",
                "            vertical-align: middle;\n",
                "        }\n",
                "\n",
                "        @keyframes spin {\n",
                "            to {\n",
                "                transform: rotate(360deg);\n",
                "            }\n",
                "        }\n",
                "\n",
                "        .hidden {\n",
                "            display: none;\n",
                "        }\n",
                "    </style>\n",
                "</head>\n",
                "\n",
                "<body>\n",
                "\n",
                "    <div class=\"container\">\n",
                "        <div>\n",
                "            <h1>ğŸ‘ï¸ AI Vision Demo</h1>\n",
                "            <div class=\"subtitle\">Powered by Florence-2 VLM (v1.0)</div>\n",
                "        </div>\n",
                "\n",
                "        <!-- Desktop Only: QR Code -->\n",
                "        <div class=\"card qr-section\">\n",
                "            <img src=\"/qrcode\" alt=\"Scan to use on mobile\">\n",
                "            <p>ğŸ“± æ‰‹æœºæ‰«ç ä½“éªŒ</p>\n",
                "        </div>\n",
                "\n",
                "        <!-- Main Interaction Area -->\n",
                "        <div class=\"card\">\n",
                "            <!-- File Upload -->\n",
                "            <div class=\"upload-area\" id=\"drop-zone\">\n",
                "                <span class=\"icon\">ğŸ“·</span>\n",
                "                <p class=\"mobile-hidden\">ç‚¹å‡»ä¸Šä¼ å›¾ç‰‡</p>\n",
                "                <p class=\"desktop-hidden\">ç‚¹å‡»æ‹ç…§æˆ–ä¸Šä¼ å›¾ç‰‡</p>\n",
                "                <input type=\"file\" id=\"file-input\" accept=\"image/*\">\n",
                "            </div>\n",
                "\n",
                "            <!-- Webcam Trigger -->\n",
                "            <button id=\"cam-btn\" class=\"btn mobile-hidden\" style=\"background-color: #333; margin-top: 10px;\">ğŸ’»\n",
                "                ä½¿ç”¨ç”µè„‘æ‘„åƒå¤´</button>\n",
                "\n",
                "            <!-- Camera View (Hidden by default) -->\n",
                "            <div id=\"camera-container\" class=\"hidden\" style=\"margin-top: 20px; text-align: center;\">\n",
                "                <video id=\"video-feed\" autoplay playsinline\n",
                "                    style=\"width: 100%; border-radius: 8px; border: 2px solid #4CAF50;\"></video>\n",
                "                <button id=\"snap-btn\" class=\"btn\">ğŸ“¸ æ‹ç…§</button>\n",
                "                <button id=\"close-cam-btn\" class=\"btn\" style=\"background-color: #666;\">å–æ¶ˆ</button>\n",
                "            </div>\n",
                "\n",
                "            <div id=\"preview-container\" class=\"hidden\" style=\"margin-top: 20px;\">\n",
                "                <canvas id=\"canvas\" class=\"hidden\"></canvas>\n",
                "                <img id=\"preview-img\" class=\"preview-img\" src=\"\" alt=\"Preview\">\n",
                "                <button id=\"upload-btn\" class=\"btn\">ğŸš€ å¼€å§‹è¯†åˆ«</button>\n",
                "            </div>\n",
                "        </div>\n",
                "\n",
                "        <!-- Result Area -->\n",
                "        <div id=\"result-card\" class=\"card hidden\">\n",
                "            <h3>ğŸ“ è¯†åˆ«ç»“æœ</h3>\n",
                "            <div id=\"result-content\" class=\"result-text\"></div>\n",
                "        </div>\n",
                "    </div>\n",
                "\n",
                "    <script>\n",
                "        // Global Audio Helpers\n",
                "        const fileInput = document.getElementById('file-input');\n",
                "        const previewContainer = document.getElementById('preview-container');\n",
                "        const previewImg = document.getElementById('preview-img');\n",
                "        const uploadBtn = document.getElementById('upload-btn');\n",
                "        const resultCard = document.getElementById('result-card');\n",
                "        const resultContent = document.getElementById('result-content');\n",
                "\n",
                "        // Camera Elements\n",
                "        const camBtn = document.getElementById('cam-btn');\n",
                "        const cameraContainer = document.getElementById('camera-container');\n",
                "        const video = document.getElementById('video-feed');\n",
                "        const snapBtn = document.getElementById('snap-btn');\n",
                "        const closeCamBtn = document.getElementById('close-cam-btn');\n",
                "        const canvas = document.getElementById('canvas');\n",
                "        let stream = null;\n",
                "        let blobToSend = null; // Store blob for upload\n",
                "\n",
                "        // 1. File Selection\n",
                "        fileInput.addEventListener('change', function (e) {\n",
                "            if (this.files && this.files[0]) {\n",
                "                const file = this.files[0];\n",
                "                blobToSend = file; // Set blob\n",
                "                const reader = new FileReader();\n",
                "                reader.onload = function (e) {\n",
                "                    previewImg.src = e.target.result;\n",
                "                    previewContainer.classList.remove('hidden');\n",
                "                    cameraContainer.classList.add('hidden');\n",
                "                    resultCard.classList.add('hidden');\n",
                "                    stopCamera();\n",
                "                }\n",
                "                reader.readAsDataURL(file);\n",
                "            }\n",
                "        });\n",
                "\n",
                "        // 2. Open Camera\n",
                "        camBtn.addEventListener('click', async () => {\n",
                "            try {\n",
                "                stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: \"environment\" } });\n",
                "                video.srcObject = stream;\n",
                "                cameraContainer.classList.remove('hidden');\n",
                "                previewContainer.classList.add('hidden');\n",
                "                resultCard.classList.add('hidden');\n",
                "            } catch (err) {\n",
                "                alert(\"æ— æ³•è®¿é—®æ‘„åƒå¤´: \" + err.message);\n",
                "            }\n",
                "        });\n",
                "\n",
                "        // 3. Close Camera\n",
                "        closeCamBtn.addEventListener('click', () => {\n",
                "            stopCamera();\n",
                "            cameraContainer.classList.add('hidden');\n",
                "        });\n",
                "\n",
                "        function stopCamera() {\n",
                "            if (stream) {\n",
                "                stream.getTracks().forEach(track => track.stop());\n",
                "                stream = null;\n",
                "            }\n",
                "        }\n",
                "\n",
                "        // 4. Snap Photo\n",
                "        snapBtn.addEventListener('click', () => {\n",
                "            const context = canvas.getContext('2d');\n",
                "            canvas.width = video.videoWidth;\n",
                "            canvas.height = video.videoHeight;\n",
                "            context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
                "\n",
                "            // Convert to Blob\n",
                "            canvas.toBlob(blob => {\n",
                "                blobToSend = blob;\n",
                "                previewImg.src = URL.createObjectURL(blob);\n",
                "                previewContainer.classList.remove('hidden');\n",
                "                cameraContainer.classList.add('hidden');\n",
                "                stopCamera();\n",
                "            }, 'image/jpeg');\n",
                "        });\n",
                "\n",
                "        // 5. Upload Logic\n",
                "        // 5. Upload Logic\n",
                "        // 5. Upload Logic (Refactored for Lesson 26 Pipeline: Vision -> Translation)\n",
                "        uploadBtn.addEventListener('click', async function () {\n",
                "            if (!blobToSend) return alert(\"è¯·å…ˆé€‰æ‹©å›¾ç‰‡æˆ–æ‹ç…§\");\n",
                "\n",
                "            const formData = new FormData();\n",
                "            formData.append('file', blobToSend, \"capture.jpg\");\n",
                "\n",
                "            // UI State: Loading Vision\n",
                "            uploadBtn.disabled = true;\n",
                "            let startTime = Date.now();\n",
                "            let timerInterval = setInterval(() => {\n",
                "                let elapsed = ((Date.now() - startTime) / 1000).toFixed(1);\n",
                "                uploadBtn.innerHTML = `<span class=\"loader\"></span> æ­£åœ¨æ¨ç†ä¸­... (${elapsed}s)`;\n",
                "            }, 100);\n",
                "\n",
                "            resultContent.innerText = '';\n",
                "\n",
                "            try {\n",
                "                // ==========================\n",
                "                // Step 1: Vision (Florence-2)\n",
                "                // ==========================\n",
                "                const response = await fetch('/upload', { method: 'POST', body: formData });\n",
                "                if (!response.ok) throw new Error('Network error on /upload');\n",
                "\n",
                "                const data = await response.json();\n",
                "\n",
                "                // Clear Vision timer\n",
                "                clearInterval(timerInterval);\n",
                "\n",
                "                if (data.error) {\n",
                "                    resultContent.innerText = \"âŒ é”™è¯¯: \" + data.error;\n",
                "                    return;\n",
                "                }\n",
                "\n",
                "                const visionTime = data.cost_time;\n",
                "                const captionEn = data.caption_en || data.label; // Fallback for old API\n",
                "\n",
                "                // Display Step 1 Result (Immediate English)\n",
                "                resultCard.classList.remove('hidden');\n",
                "                resultContent.innerHTML = `\n",
                "                    <div style=\"margin-bottom:10px;\">\n",
                "                        <strong>ğŸ‡¬ğŸ‡§ EN:</strong> ${captionEn}\n",
                "                        <div style=\"font-size:0.8em; color:#888;\">â±ï¸ è§†è§‰è€—æ—¶: ${visionTime}s</div>\n",
                "                    </div>\n",
                "                `;\n",
                "\n",
                "                } catch (error) {\n",
                "                clearInterval(timerInterval);\n",
                "                alert('ä¸Šä¼ å¤±è´¥ï¼Œè¯·é‡è¯•');\n",
                "                console.error(error);\n",
                "                resultContent.innerText = \"âŒ ç³»ç»Ÿé”™è¯¯: \" + error.message;\n",
                "            } finally {\n",
                "                // UI State: Reset\n",
                "                uploadBtn.disabled = false;\n",
                "                uploadBtn.innerText = 'ğŸš€ å¼€å§‹è¯†åˆ«';\n",
                "            }\n",
                "        });\n",
                "    </script>\n",
                "</body>\n",
                "\n",
                "</html>\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. ç”Ÿæˆåç«¯ (app.py)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile app.py\n",
                "import os\n",
                "# Fix for MPS 'aten::isin' error: Enable fallback to CPU for unsupported ops\n",
                "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
                "# Suppress huggingface/tokenizers parallelism warning\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "import uvicorn\n",
                "from fastapi import FastAPI, UploadFile, File\n",
                "from fastapi.responses import HTMLResponse, Response\n",
                "from transformers import AutoProcessor, AutoModelForCausalLM\n",
                "from PIL import Image\n",
                "import io\n",
                "import socket\n",
                "import qrcode\n",
                "import sys\n",
                "import torch\n",
                "import pathlib\n",
                "import pathlib\n",
                "import time\n",
                "import warnings # Added for warning suppression\n",
                "\n",
                "# Filter out specific library warnings to keep console clean for students\n",
                "warnings.filterwarnings(\"ignore\", message=\".*To copy construct from a tensor.*\")\n",
                "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"transformers\")\n",
                "\n",
                "# 1. åˆå§‹åŒ– FastAPI åº”ç”¨\n",
                "app = FastAPI(title=\"Lesson 25 Vision Demo (Florence-2)\")\n",
                "\n",
                "# Mock flash_attn for Mac compatibility\n",
                "from unittest.mock import MagicMock\n",
                "sys.modules[\"flash_attn\"] = MagicMock()\n",
                "sys.modules[\"flash_attn\"].__spec__ = MagicMock()\n",
                "\n",
                "# Helper: Get Local IP\n",
                "def get_local_ip():\n",
                "    try:\n",
                "        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
                "        s.connect((\"8.8.8.8\", 80))\n",
                "        ip = s.getsockname()[0]\n",
                "        s.close()\n",
                "        return ip\n",
                "    except:\n",
                "        return \"127.0.0.1\"\n",
                "\n",
                "# 2. é¢„åŠ è½½æ¨¡å‹ (ä½¿ç”¨ Microsoft Florence-2-base)\n",
                "# ä¼˜å…ˆæ£€æŸ¥æœ¬åœ°æ¨¡å‹\n",
                "local_model_path = \"./models/florence-2-base\"\n",
                "if os.path.exists(local_model_path):\n",
                "    print(f\"ğŸ“‚ å‘ç°æœ¬åœ°æ¨¡å‹ path: {local_model_path}\")\n",
                "    model_id = local_model_path\n",
                "else:\n",
                "    print(f\"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå‡†å¤‡ä» HuggingFace ä¸‹è½½...\")\n",
                "    model_id = \"microsoft/Florence-2-base\"\n",
                "# è‡ªåŠ¨æ£€æµ‹è®¾å¤‡: ä¼˜å…ˆ MPS (Mac), å…¶æ¬¡ CPU\n",
                "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
                "# Florence-2 åœ¨ GPU/MPS ä¸Šé€šå¸¸ä½¿ç”¨ float16ï¼Œä½†åœ¨ CPU ä¸Šä½¿ç”¨ float32\n",
                "torch_dtype = torch.float16 if device != \"cpu\" else torch.float32\n",
                "\n",
                "model = None\n",
                "processor = None\n",
                "\n",
                "try:\n",
                "    print(\"=\"*50)\n",
                "    print(f\"ğŸš€ æ­£åœ¨åŠ è½½ Florence-2 æ¨¡å‹...\")\n",
                "    print(f\"ğŸ“‚ æ¨¡å‹æ¥æº: {model_id}\")\n",
                "    print(f\"ğŸ–¥ï¸  è¿è¡Œè®¾å¤‡: {device.upper()}\")\n",
                "    \n",
                "    # å¦‚æœå‘ç°æ˜¯æœ¬åœ°è·¯å¾„ï¼Œå¼ºåˆ¶ç¦»çº¿æ¨¡å¼\n",
                "    local_files_only = False\n",
                "    if os.path.isdir(model_id):\n",
                "        print(f\"ğŸ”Œ æ£€æµ‹åˆ°æœ¬åœ°è·¯å¾„ï¼Œå¯ç”¨ç¦»çº¿æ¨¡å¼ (local_files_only=True)\")\n",
                "        local_files_only = True\n",
                "        os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
                "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
                "    \n",
                "    if model_id == \"microsoft/Florence-2-base\" and not local_files_only:\n",
                "        print(\"ç¬¬ä¸€æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ (çº¦ 1.5GB)ï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
                "    \n",
                "    model = AutoModelForCausalLM.from_pretrained(\n",
                "        model_id, \n",
                "        trust_remote_code=True, \n",
                "        torch_dtype=torch_dtype,\n",
                "        local_files_only=local_files_only\n",
                "    ).to(device)\n",
                "    \n",
                "    processor = AutoProcessor.from_pretrained(\n",
                "        model_id, \n",
                "        trust_remote_code=True,\n",
                "        local_files_only=local_files_only\n",
                "    )\n",
                "    \n",
                "    print(\"âœ¨ Florence-2 æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
                "    print(\"=\"*50)\n",
                "except Exception as e:\n",
                "    import traceback\n",
                "    print(f\"\\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
                "    print(\"å¯èƒ½æ˜¯ transformer ç‰ˆæœ¬è¿‡ä½æˆ–ä¾èµ–ç¼ºå¤±ã€‚è¯·å°è¯•è¿è¡Œ: pip install -U transformers timm einops\")\n",
                "    traceback.print_exc()\n",
                "\n",
                "# 3. æ¨¡å‹é¢„çƒ­ (Warmup) - æ¶ˆé™¤ç¬¬ä¸€æ¬¡è¿è¡Œçš„å¡é¡¿\n",
                "def warmup_model():\n",
                "    if not model or not processor: return\n",
                "    print(\"ğŸ”¥ æ­£åœ¨é¢„çƒ­æ¨¡å‹... (æ¶ˆé™¤é¦–æ¬¡æ¨ç†å¡é¡¿)\")\n",
                "    try:\n",
                "        # åˆ›å»ºä¸€ä¸ªæå…¶å¾®å°çš„ Dummy è¾“å…¥\n",
                "        dummy_img = Image.new('RGB', (64, 64), color='white')\n",
                "        dummy_prompt = \"<CAPTION>\"\n",
                "        inputs = processor(text=dummy_prompt, images=dummy_img, return_tensors=\"pt\").to(device, torch_dtype)\n",
                "        # å¼ºåˆ¶è¿è¡Œä¸€æ¬¡ç”Ÿæˆ\n",
                "        model.generate(\n",
                "            input_ids=inputs[\"input_ids\"],\n",
                "            pixel_values=inputs[\"pixel_values\"],\n",
                "            max_new_tokens=5, \n",
                "            do_sample=False,\n",
                "            num_beams=1,\n",
                "        )\n",
                "        print(\"âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼\")\n",
                "    except Exception as e:\n",
                "        print(f\"âš ï¸ é¢„çƒ­å¤±è´¥ (ä¸å½±å“ä¸»åŠŸèƒ½): {e}\")\n",
                "\n",
                "# æ‰§è¡Œé¢„çƒ­\n",
                "warmup_model()\n",
                "\n",
                "@app.get(\"/\", response_class=HTMLResponse)\n",
                "def home():\n",
                "    \"\"\"Serve the frontend HTML\"\"\"\n",
                "    return pathlib.Path(\"index.html\").read_text(encoding=\"utf-8\")\n",
                "\n",
                "@app.get(\"/qrcode\")\n",
                "def get_qr_image():\n",
                "    \"\"\"Generate QR Code for the server URL\"\"\"\n",
                "    ip = get_local_ip()\n",
                "    url = f\"http://{ip}:8000\"\n",
                "    print(f\"ğŸ“± QR Code URL: {url}\")\n",
                "    \n",
                "    qr = qrcode.QRCode(box_size=10, border=4)\n",
                "    qr.add_data(url)\n",
                "    qr.make(fit=True)\n",
                "    img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
                "    \n",
                "    buf = io.BytesIO()\n",
                "    img.save(buf, format=\"PNG\")\n",
                "    buf.seek(0)\n",
                "    return Response(content=buf.getvalue(), media_type=\"image/png\")\n",
                "\n",
                "@app.post(\"/upload\")\n",
                "async def upload_image(file: UploadFile = File(...)):\n",
                "    \"\"\"\n",
                "    æ¥æ”¶æ‰‹æœºä¸Šä¼ çš„å›¾ç‰‡ï¼Œå¹¶è¿”å›è¯¦ç»†æè¿° (Detailed Caption)\n",
                "    \"\"\"\n",
                "    global model, processor\n",
                "    \n",
                "    if not model or not processor:\n",
                "        return {\"error\": \"Model not loaded. Check server logs.\"}\n",
                "\n",
                "    try:\n",
                "        # è¯»å–å›¾ç‰‡æ•°æ®\n",
                "        contents = await file.read()\n",
                "        image = Image.open(io.BytesIO(contents))\n",
                "        if image.mode != \"RGB\":\n",
                "            image = image.convert(\"RGB\")\n",
                "        \n",
                "        # æ„é€ æç¤ºè¯ task\n",
                "        prompt = \"<MORE_DETAILED_CAPTION>\"\n",
                "        \n",
                "        # æ‰“å°æ—¥å¿—åˆ°æ§åˆ¶å°\n",
                "        print(f\"\\nğŸ“¸ æ”¶åˆ°å›¾ç‰‡: {file.filename}\")\n",
                "        \n",
                "        # è®¡æ—¶å¼€å§‹\n",
                "        start_time = time.time()\n",
                "        \n",
                "        # é¢„å¤„ç†è¾“å…¥\n",
                "        inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
                "\n",
                "        # ç”Ÿæˆæè¿°\n",
                "        generated_ids = model.generate(\n",
                "            input_ids=inputs[\"input_ids\"],\n",
                "            pixel_values=inputs[\"pixel_values\"],\n",
                "            max_new_tokens=1024,\n",
                "            do_sample=False,\n",
                "            num_beams=3,\n",
                "        )\n",
                "        \n",
                "        # è§£ç è¾“å‡º\n",
                "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
                "        \n",
                "        # åå¤„ç† (Florence-2 ç‰¹æœ‰)\n",
                "        parsed_answer = processor.post_process_generation(\n",
                "            generated_text, \n",
                "            task=prompt, \n",
                "            image_size=(image.width, image.height)\n",
                "        )\n",
                "        \n",
                "        # è®¡æ—¶ç»“æŸ\n",
                "        end_time = time.time()\n",
                "        cost_time = round(end_time - start_time, 2)\n",
                "        \n",
                "        # è·å–æœ€ç»ˆæ–‡æœ¬\n",
                "        caption = parsed_answer[prompt]\n",
                "        \n",
                "        # æ‰“å°æ—¥å¿—åˆ°æ§åˆ¶å°\n",
                "        print(f\"â±ï¸ æ¨ç†è€—æ—¶: {cost_time}s\")\n",
                "        print(f\"ğŸ¤– Florence-2 æè¿°:\\n{caption}\")\n",
                "        \n",
                "        return {\n",
                "            \"label\": caption,\n",
                "            \"cost_time\": cost_time\n",
                "        }\n",
                "    except Exception as e:\n",
                "        import traceback\n",
                "        print(f\"âŒ å¤„ç†å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
                "        traceback.print_exc()\n",
                "        return {\"error\": str(e)}\n",
                "\n",
                "def get_local_ip():\n",
                "    \"\"\"è·å–æœ¬æœºå±€åŸŸç½‘IP\"\"\"\n",
                "    try:\n",
                "        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
                "        s.connect((\"8.8.8.8\", 80))\n",
                "        ip = s.getsockname()[0]\n",
                "        s.close()\n",
                "        return ip\n",
                "    except:\n",
                "        return \"127.0.0.1\"\n",
                "\n",
                "def print_qr_code(url):\n",
                "    \"\"\"åœ¨ç»ˆç«¯æ‰“å°äºŒç»´ç \"\"\"\n",
                "    try:\n",
                "        qr = qrcode.QRCode()\n",
                "        qr.add_data(url)\n",
                "        qr.print_ascii(invert=True)\n",
                "        print(f\"\\nğŸ“± æ‰‹æœºæ‰«ç ä½“éªŒ: {url}\")\n",
                "    except Exception:\n",
                "        print(f\"\\nâš ï¸ æ— æ³•ç”ŸæˆäºŒç»´ç ï¼Œè¯·æ‰‹åŠ¨è®¿é—®: {url}\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    ip = get_local_ip()\n",
                "    port = 8000\n",
                "    url = f\"http://{ip}:{port}/docs\"\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*50)\n",
                "    print(f\"ğŸš€ æœåŠ¡å¯åŠ¨ä¸­...\")\n",
                "    print(f\"Running on: {url}\")\n",
                "    print(\"=\"*50)\n",
                "    \n",
                "    # æ‰“å°äºŒç»´ç ä¾›æ‰«æ\n",
                "    print_qr_code(url)\n",
                "    \n",
                "    print(\"\\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡\")\n",
                "    \n",
                "    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. è¿è¡ŒæœåŠ¡\n",
                "æœ€åï¼Œåœ¨ç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python app.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lesson 26: 8. å†æ¬¡è¿­ä»£: å¼•å…¥ äº‘ç«¯ç¿»è¯‘ & è¯­éŸ³åˆæˆ (TTS) \n",
                "åœ¨è¿™ä¸ªç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬å°†å¼•å…¥:\n",
                "- **SiliconFlow API**: ç”¨äº DeepSeek ç¿»è¯‘ (è‹± -> ä¸­) å’Œ CosyVoice2 è¯­éŸ³åˆæˆã€‚\n",
                "- **Florence-2**: ä¾ç„¶è´Ÿè´£è§†è§‰è¯†åˆ«ã€‚\n",
                "\n",
                "æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°çš„å‰ç«¯ `lesson26.html` å’Œæ–°çš„åç«¯ `app_v2.py`ã€‚\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile lesson26.html\n",
                "<!DOCTYPE html>\n",
                "<html lang=\"zh-CN\">\n",
                "\n",
                "<head>\n",
                "    <meta charset=\"UTF-8\">\n",
                "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\">\n",
                "    <title>AI Vision Demo (Florence-2)</title>\n",
                "    <style>\n",
                "        :root {\n",
                "            --primary-color: #4CAF50;\n",
                "            --bg-color: #1e1e1e;\n",
                "            --card-bg: #252526;\n",
                "            --text-color: #ddd;\n",
                "        }\n",
                "\n",
                "        body {\n",
                "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;\n",
                "            background-color: var(--bg-color);\n",
                "            color: var(--text-color);\n",
                "            display: flex;\n",
                "            flex-direction: column;\n",
                "            align-items: center;\n",
                "            min-height: 100vh;\n",
                "            margin: 0;\n",
                "            padding: 20px;\n",
                "        }\n",
                "\n",
                "        .container {\n",
                "            width: 100%;\n",
                "            max-width: 600px;\n",
                "            display: flex;\n",
                "            flex-direction: column;\n",
                "            gap: 20px;\n",
                "        }\n",
                "\n",
                "        h1 {\n",
                "            text-align: center;\n",
                "            color: var(--primary-color);\n",
                "            margin-bottom: 5px;\n",
                "        }\n",
                "\n",
                "        .subtitle {\n",
                "            text-align: center;\n",
                "            color: #888;\n",
                "            font-size: 0.9em;\n",
                "            margin-bottom: 20px;\n",
                "        }\n",
                "\n",
                "        .card {\n",
                "            background-color: var(--card-bg);\n",
                "            padding: 20px;\n",
                "            border-radius: 12px;\n",
                "            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);\n",
                "        }\n",
                "\n",
                "        /* QR Code Section - Hidden on Mobile */\n",
                "        .qr-section {\n",
                "            text-align: center;\n",
                "            display: flex;\n",
                "            flex-direction: column;\n",
                "            align-items: center;\n",
                "            gap: 10px;\n",
                "        }\n",
                "\n",
                "        .qr-section img {\n",
                "            width: 180px;\n",
                "            height: 180px;\n",
                "            border-radius: 8px;\n",
                "            border: 4px solid white;\n",
                "        }\n",
                "\n",
                "        @media (max-width: 600px) {\n",
                "            .qr-section {\n",
                "                display: none;\n",
                "            }\n",
                "\n",
                "            .mobile-hidden {\n",
                "                display: none;\n",
                "            }\n",
                "        }\n",
                "\n",
                "        @media (min-width: 601px) {\n",
                "            .desktop-hidden {\n",
                "                display: none;\n",
                "            }\n",
                "        }\n",
                "\n",
                "        /* Upload Section */\n",
                "        .upload-area {\n",
                "            border: 2px dashed #444;\n",
                "            border-radius: 8px;\n",
                "            padding: 30px;\n",
                "            text-align: center;\n",
                "            cursor: pointer;\n",
                "            transition: border-color 0.3s;\n",
                "            position: relative;\n",
                "        }\n",
                "\n",
                "        .upload-area:hover {\n",
                "            border-color: var(--primary-color);\n",
                "        }\n",
                "\n",
                "        .upload-area input[type=\"file\"] {\n",
                "            position: absolute;\n",
                "            top: 0;\n",
                "            left: 0;\n",
                "            width: 100%;\n",
                "            height: 100%;\n",
                "            opacity: 0;\n",
                "            cursor: pointer;\n",
                "        }\n",
                "\n",
                "        .icon {\n",
                "            font-size: 48px;\n",
                "            margin-bottom: 10px;\n",
                "            display: block;\n",
                "        }\n",
                "\n",
                "        .btn {\n",
                "            background-color: var(--primary-color);\n",
                "            color: white;\n",
                "            border: none;\n",
                "            padding: 12px 24px;\n",
                "            border-radius: 6px;\n",
                "            font-size: 16px;\n",
                "            font-weight: bold;\n",
                "            cursor: pointer;\n",
                "            width: 100%;\n",
                "            margin-top: 15px;\n",
                "            transition: background-color 0.2s;\n",
                "        }\n",
                "\n",
                "        .btn:disabled {\n",
                "            background-color: #555;\n",
                "            cursor: not-allowed;\n",
                "        }\n",
                "\n",
                "        /* Result Section */\n",
                "        .preview-img {\n",
                "            max-width: 100%;\n",
                "            border-radius: 8px;\n",
                "            margin-bottom: 15px;\n",
                "            border: 1px solid #444;\n",
                "        }\n",
                "\n",
                "        .result-text {\n",
                "            font-size: 1.1em;\n",
                "            line-height: 1.6;\n",
                "            background: #333;\n",
                "            padding: 15px;\n",
                "            border-radius: 8px;\n",
                "            border-left: 4px solid var(--primary-color);\n",
                "        }\n",
                "\n",
                "        .loader {\n",
                "            display: inline-block;\n",
                "            width: 20px;\n",
                "            height: 20px;\n",
                "            border: 3px solid rgba(255, 255, 255, .3);\n",
                "            border-radius: 50%;\n",
                "            border-top-color: #fff;\n",
                "            animation: spin 1s ease-in-out infinite;\n",
                "            margin-right: 10px;\n",
                "            vertical-align: middle;\n",
                "        }\n",
                "\n",
                "        @keyframes spin {\n",
                "            to {\n",
                "                transform: rotate(360deg);\n",
                "            }\n",
                "        }\n",
                "\n",
                "        .hidden {\n",
                "            display: none;\n",
                "        }\n",
                "    </style>\n",
                "</head>\n",
                "\n",
                "<body>\n",
                "\n",
                "    <div class=\"container\">\n",
                "        <div>\n",
                "            <h1>ğŸ‘ï¸ AI Vision Demo</h1>\n",
                "            <div class=\"subtitle\">Powered by Florence-2 VLM (v1.0)</div>\n",
                "        </div>\n",
                "\n",
                "        <!-- Desktop Only: QR Code -->\n",
                "        <div class=\"card qr-section\">\n",
                "            <img src=\"/qrcode\" alt=\"Scan to use on mobile\">\n",
                "            <p>ğŸ“± æ‰‹æœºæ‰«ç ä½“éªŒ</p>\n",
                "        </div>\n",
                "\n",
                "        <!-- Main Interaction Area -->\n",
                "        <div class=\"card\">\n",
                "            <!-- File Upload -->\n",
                "            <div class=\"upload-area\" id=\"drop-zone\">\n",
                "                <span class=\"icon\">ğŸ“·</span>\n",
                "                <p class=\"mobile-hidden\">ç‚¹å‡»ä¸Šä¼ å›¾ç‰‡</p>\n",
                "                <p class=\"desktop-hidden\">ç‚¹å‡»æ‹ç…§æˆ–ä¸Šä¼ å›¾ç‰‡</p>\n",
                "                <input type=\"file\" id=\"file-input\" accept=\"image/*\">\n",
                "            </div>\n",
                "\n",
                "            <!-- Webcam Trigger -->\n",
                "            <button id=\"cam-btn\" class=\"btn mobile-hidden\" style=\"background-color: #333; margin-top: 10px;\">ğŸ’»\n",
                "                ä½¿ç”¨ç”µè„‘æ‘„åƒå¤´</button>\n",
                "\n",
                "            <!-- Camera View (Hidden by default) -->\n",
                "            <div id=\"camera-container\" class=\"hidden\" style=\"margin-top: 20px; text-align: center;\">\n",
                "                <video id=\"video-feed\" autoplay playsinline\n",
                "                    style=\"width: 100%; border-radius: 8px; border: 2px solid #4CAF50;\"></video>\n",
                "                <button id=\"snap-btn\" class=\"btn\">ğŸ“¸ æ‹ç…§</button>\n",
                "                <button id=\"close-cam-btn\" class=\"btn\" style=\"background-color: #666;\">å–æ¶ˆ</button>\n",
                "            </div>\n",
                "\n",
                "            <div id=\"preview-container\" class=\"hidden\" style=\"margin-top: 20px;\">\n",
                "                <canvas id=\"canvas\" class=\"hidden\"></canvas>\n",
                "                <img id=\"preview-img\" class=\"preview-img\" src=\"\" alt=\"Preview\">\n",
                "                <button id=\"upload-btn\" class=\"btn\">ğŸš€ å¼€å§‹è¯†åˆ«</button>\n",
                "            </div>\n",
                "        </div>\n",
                "\n",
                "        <!-- Result Area -->\n",
                "        <div id=\"result-card\" class=\"card hidden\">\n",
                "            <h3>ğŸ“ è¯†åˆ«ç»“æœ</h3>\n",
                "            <div id=\"result-content\" class=\"result-text\"></div>\n",
                "        </div>\n",
                "    </div>\n",
                "\n",
                "    <script>\n",
                "        // Global Audio Helpers\n",
                "        window.toggleAudio = function (uniqueId) {\n",
                "            const audio = document.getElementById('audio-' + uniqueId);\n",
                "            const btn = document.getElementById('btn-' + uniqueId);\n",
                "\n",
                "            if (audio.paused) {\n",
                "                audio.play().catch(e => console.warn(\"Play failed:\", e));\n",
                "                btn.innerHTML = '<span>â¸ï¸</span> ç‚¹å‡»æš‚åœ';\n",
                "                btn.style.color = '#ff9800'; // Active color\n",
                "                btn.style.borderColor = '#ff9800';\n",
                "            } else {\n",
                "                audio.pause();\n",
                "                btn.innerHTML = '<span>â–¶ï¸</span> ç‚¹å‡»æ’­æ”¾è¯­éŸ³';\n",
                "                btn.style.color = '#4CAF50'; // Default color\n",
                "                btn.style.borderColor = '#4CAF50';\n",
                "            }\n",
                "        };\n",
                "\n",
                "        window.resetAudio = function (uniqueId) {\n",
                "            const btn = document.getElementById('btn-' + uniqueId);\n",
                "            btn.innerHTML = '<span>â–¶ï¸</span> ç‚¹å‡»æ’­æ”¾è¯­éŸ³';\n",
                "            btn.style.color = '#4CAF50';\n",
                "            btn.style.borderColor = '#4CAF50';\n",
                "        };\n",
                "\n",
                "        const fileInput = document.getElementById('file-input');\n",
                "        const previewContainer = document.getElementById('preview-container');\n",
                "        const previewImg = document.getElementById('preview-img');\n",
                "        const uploadBtn = document.getElementById('upload-btn');\n",
                "        const resultCard = document.getElementById('result-card');\n",
                "        const resultContent = document.getElementById('result-content');\n",
                "\n",
                "        // Camera Elements\n",
                "        const camBtn = document.getElementById('cam-btn');\n",
                "        const cameraContainer = document.getElementById('camera-container');\n",
                "        const video = document.getElementById('video-feed');\n",
                "        const snapBtn = document.getElementById('snap-btn');\n",
                "        const closeCamBtn = document.getElementById('close-cam-btn');\n",
                "        const canvas = document.getElementById('canvas');\n",
                "        let stream = null;\n",
                "        let blobToSend = null; // Store blob for upload\n",
                "\n",
                "        // 1. File Selection\n",
                "        fileInput.addEventListener('change', function (e) {\n",
                "            if (this.files && this.files[0]) {\n",
                "                const file = this.files[0];\n",
                "                blobToSend = file; // Set blob\n",
                "                const reader = new FileReader();\n",
                "                reader.onload = function (e) {\n",
                "                    previewImg.src = e.target.result;\n",
                "                    previewContainer.classList.remove('hidden');\n",
                "                    cameraContainer.classList.add('hidden');\n",
                "                    resultCard.classList.add('hidden');\n",
                "                    stopCamera();\n",
                "                }\n",
                "                reader.readAsDataURL(file);\n",
                "            }\n",
                "        });\n",
                "\n",
                "        // 2. Open Camera\n",
                "        camBtn.addEventListener('click', async () => {\n",
                "            try {\n",
                "                stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: \"environment\" } });\n",
                "                video.srcObject = stream;\n",
                "                cameraContainer.classList.remove('hidden');\n",
                "                previewContainer.classList.add('hidden');\n",
                "                resultCard.classList.add('hidden');\n",
                "            } catch (err) {\n",
                "                alert(\"æ— æ³•è®¿é—®æ‘„åƒå¤´: \" + err.message);\n",
                "            }\n",
                "        });\n",
                "\n",
                "        // 3. Close Camera\n",
                "        closeCamBtn.addEventListener('click', () => {\n",
                "            stopCamera();\n",
                "            cameraContainer.classList.add('hidden');\n",
                "        });\n",
                "\n",
                "        function stopCamera() {\n",
                "            if (stream) {\n",
                "                stream.getTracks().forEach(track => track.stop());\n",
                "                stream = null;\n",
                "            }\n",
                "        }\n",
                "\n",
                "        // 4. Snap Photo\n",
                "        snapBtn.addEventListener('click', () => {\n",
                "            const context = canvas.getContext('2d');\n",
                "            canvas.width = video.videoWidth;\n",
                "            canvas.height = video.videoHeight;\n",
                "            context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
                "\n",
                "            // Convert to Blob\n",
                "            canvas.toBlob(blob => {\n",
                "                blobToSend = blob;\n",
                "                previewImg.src = URL.createObjectURL(blob);\n",
                "                previewContainer.classList.remove('hidden');\n",
                "                cameraContainer.classList.add('hidden');\n",
                "                stopCamera();\n",
                "            }, 'image/jpeg');\n",
                "        });\n",
                "\n",
                "        // 5. Upload Logic\n",
                "        // 5. Upload Logic\n",
                "        // 5. Upload Logic (Refactored for Lesson 26 Pipeline: Vision -> Translation)\n",
                "        uploadBtn.addEventListener('click', async function () {\n",
                "            if (!blobToSend) return alert(\"è¯·å…ˆé€‰æ‹©å›¾ç‰‡æˆ–æ‹ç…§\");\n",
                "\n",
                "            const formData = new FormData();\n",
                "            formData.append('file', blobToSend, \"capture.jpg\");\n",
                "\n",
                "            // UI State: Loading Vision\n",
                "            uploadBtn.disabled = true;\n",
                "            let startTime = Date.now();\n",
                "            let timerInterval = setInterval(() => {\n",
                "                let elapsed = ((Date.now() - startTime) / 1000).toFixed(1);\n",
                "                uploadBtn.innerHTML = `<span class=\"loader\"></span> æ­£åœ¨æ¨ç†ä¸­... (${elapsed}s)`;\n",
                "            }, 100);\n",
                "\n",
                "            resultContent.innerText = '';\n",
                "\n",
                "            try {\n",
                "                // ==========================\n",
                "                // Step 1: Vision (Florence-2)\n",
                "                // ==========================\n",
                "                const response = await fetch('/upload', { method: 'POST', body: formData });\n",
                "                if (!response.ok) throw new Error('Network error on /upload');\n",
                "\n",
                "                const data = await response.json();\n",
                "\n",
                "                // Clear Vision timer\n",
                "                clearInterval(timerInterval);\n",
                "\n",
                "                if (data.error) {\n",
                "                    resultContent.innerText = \"âŒ é”™è¯¯: \" + data.error;\n",
                "                    return;\n",
                "                }\n",
                "\n",
                "                const visionTime = data.cost_time;\n",
                "                const captionEn = data.caption_en || data.label; // Fallback for old API\n",
                "\n",
                "                // Display Step 1 Result (Immediate English)\n",
                "                resultCard.classList.remove('hidden');\n",
                "                resultContent.innerHTML = `\n",
                "                    <div style=\"margin-bottom:10px;\">\n",
                "                        <strong>ğŸ‡¬ğŸ‡§ EN:</strong> ${captionEn}\n",
                "                        <div style=\"font-size:0.8em; color:#888;\">â±ï¸ è§†è§‰è€—æ—¶: ${visionTime}s</div>\n",
                "                    </div>\n",
                "                `;\n",
                "\n",
                "                // ==========================\n",
                "                // Step 2: Translation (Cloud Endpoint)\n",
                "                // ==========================\n",
                "                // Check if we need to translate (Lesson 26 feature)\n",
                "                // We'll optimistically try to call /translate endpoint.\n",
                "\n",
                "                uploadBtn.innerHTML = `<span class=\"loader\"></span> æ­£åœ¨ç¿»è¯‘ä¸­...`;\n",
                "\n",
                "                try {\n",
                "                    const transResponse = await fetch('/translate', {\n",
                "                        method: 'POST',\n",
                "                        headers: { 'Content-Type': 'application/json' },\n",
                "                        body: JSON.stringify({ text: captionEn })\n",
                "                    });\n",
                "\n",
                "                    if (transResponse.ok) {\n",
                "                        const transData = await transResponse.json();\n",
                "                        const captionZh = transData.caption_zh;\n",
                "                        const transTime = transData.cost_time;\n",
                "\n",
                "                        // Append Chinese Result\n",
                "                        const newHtml = `\n",
                "                            <hr style=\"border:0; border-top:1px solid #555; margin:10px 0;\">\n",
                "                            <div>\n",
                "                                <strong>ğŸ‡¨ğŸ‡³ ZH:</strong> ${captionZh}\n",
                "                                <div style=\"font-size:0.8em; color:#888;\">â±ï¸ ç¿»è¯‘è€—æ—¶: ${transTime}s</div>\n",
                "                            </div>\n",
                "                        `;\n",
                "                        resultContent.innerHTML += newHtml;\n",
                "\n",
                "                        // ==========================\n",
                "                        // Step 3: TTS (Text-to-Speech)\n",
                "                        // ==========================\n",
                "                        uploadBtn.innerHTML = `<span class=\"loader\"></span> æ­£åœ¨æœ—è¯»ä¸­...`;\n",
                "\n",
                "                        try {\n",
                "                            const ttsResponse = await fetch('/speak', {\n",
                "                                method: 'POST',\n",
                "                                headers: { 'Content-Type': 'application/json' },\n",
                "                                body: JSON.stringify({ text: captionZh })\n",
                "                            });\n",
                "\n",
                "                            if (ttsResponse.ok) {\n",
                "                                const audioBlob = await ttsResponse.blob();\n",
                "                                const audioUrl = URL.createObjectURL(audioBlob);\n",
                "                                const audio = new Audio(audioUrl);\n",
                "\n",
                "                                // Enhanced Mobile UI: Big Custom Button + Native Player\n",
                "                                const uniqueId = Date.now();\n",
                "                                const audioHtml = `\n",
                "                                    <div style=\"margin-top:15px; padding:15px; background:#f4f4f4; border-radius:12px; border:1px solid #ddd; text-align:center;\">\n",
                "                                        <div style=\"font-size:12px; color:#666; margin-bottom:10px;\">ğŸ”Š è¯­éŸ³å·²ç”Ÿæˆ (CosyVoice2)</div>\n",
                "                                        \n",
                "                                        <!-- Big Custom Play/Pause Button -->\n",
                "                                        <button id=\"btn-${uniqueId}\" onclick=\"toggleAudio(${uniqueId})\" \n",
                "                                            style=\"width:100%; padding:15px; background:white; border:2px solid #4CAF50; color:#4CAF50; border-radius:8px; font-size:16px; font-weight:bold; cursor:pointer; margin-bottom:10px; display:flex; align-items:center; justify-content:center; gap:8px;\">\n",
                "                                            <span>â–¶ï¸</span> ç‚¹å‡»æ’­æ”¾è¯­éŸ³\n",
                "                                        </button>\n",
                "\n",
                "                                        <!-- Native Player (hidden or small, for seeking) -->\n",
                "                                        <audio id=\"audio-${uniqueId}\" onended=\"resetAudio(${uniqueId})\" controls src=\"${audioUrl}\" style=\"width: 100%; height: 40px; border-radius:20px;\"></audio>\n",
                "                                    </div>\n",
                "                                `;\n",
                "                                resultContent.innerHTML += audioHtml;\n",
                "\n",
                "                                // Reset button state\n",
                "                                uploadBtn.innerHTML = `ğŸš€ å¼€å§‹è¯†åˆ«`;\n",
                "\n",
                "                                // Auto-play attempt (with icon update if successful)\n",
                "                                audio.play()\n",
                "                                    .then(() => {\n",
                "                                        // If auto-play succeeds, update the button state immediately\n",
                "                                        // We need to wait for the DOM to update first\n",
                "                                        setTimeout(() => {\n",
                "                                            const btn = document.getElementById('btn-' + uniqueId);\n",
                "                                            if (btn) {\n",
                "                                                btn.innerHTML = '<span>â¸ï¸</span> ç‚¹å‡»æš‚åœ';\n",
                "                                                btn.style.color = '#ff9800';\n",
                "                                                btn.style.borderColor = '#ff9800';\n",
                "                                            }\n",
                "                                        }, 100);\n",
                "                                    })\n",
                "                                    .catch(e => console.warn(\"Auto-play prevented:\", e));\n",
                "\n",
                "                                // Auto-scroll to show the player\n",
                "                                requestAnimationFrame(() => {\n",
                "                                    resultContent.lastElementChild.scrollIntoView({ behavior: \"smooth\", block: \"end\" });\n",
                "                                });\n",
                "                            }\n",
                "                        } catch (ttsErr) {\n",
                "                            console.log(\"TTS failed: \" + ttsErr);\n",
                "                            uploadBtn.innerHTML = `âš ï¸ è¯­éŸ³ç”Ÿæˆå¤±è´¥`;\n",
                "                        }\n",
                "\n",
                "                    } else {\n",
                "                        // 404 implies Lesson 25 backend or error\n",
                "                        console.log(\"Translation endpoint not found or error, skipping step 2.\");\n",
                "                    }\n",
                "                } catch (err) {\n",
                "                    console.log(\"Translation step skipped: \" + err);\n",
                "                }\n",
                "\n",
                "            } catch (error) {\n",
                "                clearInterval(timerInterval);\n",
                "                alert('ä¸Šä¼ å¤±è´¥ï¼Œè¯·é‡è¯•');\n",
                "                console.error(error);\n",
                "                resultContent.innerText = \"âŒ ç³»ç»Ÿé”™è¯¯: \" + error.message;\n",
                "            } finally {\n",
                "                // UI State: Reset\n",
                "                uploadBtn.disabled = false;\n",
                "                uploadBtn.innerText = 'ğŸš€ å¼€å§‹è¯†åˆ«';\n",
                "            }\n",
                "        });\n",
                "    </script>\n",
                "</body>\n",
                "\n",
                "</html>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile app_v2.py\n",
                "import os\n",
                "# Fix for MPS 'aten::isin' error: Enable fallback to CPU for unsupported ops\n",
                "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
                "# Suppress huggingface/tokenizers parallelism warning\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "import uvicorn\n",
                "from fastapi import FastAPI, UploadFile, File, Body\n",
                "from fastapi.responses import HTMLResponse, Response\n",
                "from pydantic import BaseModel\n",
                "from transformers import AutoProcessor, AutoModelForCausalLM\n",
                "from PIL import Image\n",
                "import io\n",
                "import socket\n",
                "import qrcode\n",
                "import sys\n",
                "import torch\n",
                "import pathlib\n",
                "import pathlib\n",
                "import time\n",
                "import warnings # Added for warning suppression\n",
                "from openai import OpenAI  # <--- New Import for Lesson 26\n",
                "from fastapi.responses import StreamingResponse # For Audio Stream\n",
                "\n",
                "# Filter out specific library warnings to keep console clean for students\n",
                "warnings.filterwarnings(\"ignore\", message=\".*To copy construct from a tensor.*\")\n",
                "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"transformers\")\n",
                "\n",
                "# 1. åˆå§‹åŒ– FastAPI åº”ç”¨\n",
                "app = FastAPI(title=\"Lesson 26 AI Vision Translator\")\n",
                "\n",
                "# ==========================================\n",
                "# â˜ï¸ Cloud API Configuration (Lesson 26 New)\n",
                "# ==========================================\n",
                "# å°è¯•ä»ç¯å¢ƒå˜é‡è·å– Keyï¼Œå¦‚æœæ²¡æœ‰åˆ™ç•™ç©º (ä¼šæŠ¥é”™æç¤º)\n",
                "# å°è¯•ä»ç¯å¢ƒå˜é‡è·å– Key\n",
                "SILICONFLOW_API_KEY = os.getenv(\"SILICONFLOW_API_KEY\")\n",
                "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
                "\n",
                "# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ Key\n",
                "VALID_API_KEY = SILICONFLOW_API_KEY or OPENAI_API_KEY\n",
                "\n",
                "SILICONFLOW_BASE_URL = \"https://api.siliconflow.cn/v1\"\n",
                "CLOUD_MODEL_NAME = \"deepseek-ai/DeepSeek-V3.2\" \n",
                "\n",
                "if not VALID_API_KEY:\n",
                "    print(\"\\n\" + \"!\"*50)\n",
                "    print(\"â›”ï¸ è‡´å‘½é”™è¯¯: æœªæ£€æµ‹åˆ° API Keyï¼\")\n",
                "    print(\"--------------------------------------------------\")\n",
                "    print(\"è¯·è‡³å°‘è®¾ç½®ä»¥ä¸‹å…¶ä¸­ä¸€ä¸ªç¯å¢ƒå˜é‡:\")\n",
                "    print(\"1. export SILICONFLOW_API_KEY='sk-...' (æ¨è)\")\n",
                "    print(\"2. export OPENAI_API_KEY='sk-...' (å¤‡é€‰)\")\n",
                "    print(\"!\"*50 + \"\\n\")\n",
                "    sys.exit(1) # Fail fast: ç¼ºå°‘æ ¸å¿ƒä¾èµ–ç›´æ¥é€€å‡º\n",
                "\n",
                "# Mock flash_attn for Mac compatibility\n",
                "from unittest.mock import MagicMock\n",
                "sys.modules[\"flash_attn\"] = MagicMock()\n",
                "sys.modules[\"flash_attn\"].__spec__ = MagicMock()\n",
                "\n",
                "# Helper: Get Local IP\n",
                "def get_local_ip():\n",
                "    try:\n",
                "        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
                "        s.connect((\"8.8.8.8\", 80))\n",
                "        ip = s.getsockname()[0]\n",
                "        s.close()\n",
                "        return ip\n",
                "    except:\n",
                "        return \"127.0.0.1\"\n",
                "\n",
                "# 2. é¢„åŠ è½½æ¨¡å‹ (ä½¿ç”¨ Microsoft Florence-2-base)\n",
                "local_model_path = \"./models/florence-2-base\"\n",
                "if os.path.exists(local_model_path):\n",
                "    print(f\"ğŸ“‚ å‘ç°æœ¬åœ°æ¨¡å‹ path: {local_model_path}\")\n",
                "    model_id = local_model_path\n",
                "else:\n",
                "    print(f\"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå‡†å¤‡ä» HuggingFace ä¸‹è½½...\")\n",
                "    model_id = \"microsoft/Florence-2-base\"\n",
                "\n",
                "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
                "torch_dtype = torch.float16 if device != \"cpu\" else torch.float32\n",
                "\n",
                "model = None\n",
                "processor = None\n",
                "\n",
                "try:\n",
                "    print(\"=\"*50)\n",
                "    print(f\"ğŸš€ æ­£åœ¨åŠ è½½ Florence-2 æ¨¡å‹...\")\n",
                "    print(f\"ğŸ“‚ æ¨¡å‹æ¥æº: {model_id}\")\n",
                "    print(f\"ğŸ–¥ï¸  è¿è¡Œè®¾å¤‡: {device.upper()}\")\n",
                "    \n",
                "    local_files_only = False\n",
                "    if os.path.isdir(model_id):\n",
                "        print(f\"ğŸ”Œ æ£€æµ‹åˆ°æœ¬åœ°è·¯å¾„ï¼Œå¯ç”¨ç¦»çº¿æ¨¡å¼ (local_files_only=True)\")\n",
                "        local_files_only = True\n",
                "        os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
                "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
                "    \n",
                "    model = AutoModelForCausalLM.from_pretrained(\n",
                "        model_id, \n",
                "        trust_remote_code=True, \n",
                "        torch_dtype=torch_dtype,\n",
                "        local_files_only=local_files_only\n",
                "    ).to(device)\n",
                "    \n",
                "    processor = AutoProcessor.from_pretrained(\n",
                "        model_id, \n",
                "        trust_remote_code=True,\n",
                "        local_files_only=local_files_only\n",
                "    )\n",
                "    \n",
                "    print(\"âœ¨ Florence-2 æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
                "    print(\"=\"*50)\n",
                "except Exception as e:\n",
                "    print(f\"\\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
                "\n",
                "# 3. æ¨¡å‹é¢„çƒ­\n",
                "def warmup_model():\n",
                "    if not model or not processor: return\n",
                "    print(\"ğŸ”¥ æ­£åœ¨é¢„çƒ­æ¨¡å‹... (æ¶ˆé™¤é¦–æ¬¡æ¨ç†å¡é¡¿)\")\n",
                "    try:\n",
                "        dummy_img = Image.new('RGB', (64, 64), color='white')\n",
                "        dummy_prompt = \"<CAPTION>\"\n",
                "        inputs = processor(text=dummy_prompt, images=dummy_img, return_tensors=\"pt\").to(device, torch_dtype)\n",
                "        model.generate(\n",
                "            input_ids=inputs[\"input_ids\"],\n",
                "            pixel_values=inputs[\"pixel_values\"],\n",
                "            max_new_tokens=5, \n",
                "            do_sample=False,\n",
                "            num_beams=1,\n",
                "        )\n",
                "        print(\"âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼\")\n",
                "    except Exception as e:\n",
                "        print(f\"âš ï¸ é¢„çƒ­å¤±è´¥ (ä¸å½±å“ä¸»åŠŸèƒ½): {e}\")\n",
                "\n",
                "warmup_model()\n",
                "\n",
                "# ==========================================\n",
                "# ğŸ§  new helper: Cloud Translation\n",
                "# ==========================================\n",
                "def translate_text(text: str) -> str:\n",
                "    \"\"\"è°ƒç”¨äº‘ç«¯å¤§æ¨¡å‹å°†è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡\"\"\"\n",
                "    # å°è¯•å¤šç§æ–¹å¼è·å– Key\n",
                "    api_key = SILICONFLOW_API_KEY or os.getenv(\"OPENAI_API_KEY\")\n",
                "    \n",
                "    # å³ä½¿ api_key ä¸º Noneï¼Œæˆ‘ä»¬ä¹Ÿå°è¯•åˆå§‹åŒ–ï¼Œå› ä¸º OpenAI SDK å¯èƒ½æœ‰è‡ªå·±çš„é…ç½®åŠ è½½æœºåˆ¶\n",
                "    try:\n",
                "        client = OpenAI(api_key=api_key, base_url=SILICONFLOW_BASE_URL)\n",
                "        response = client.chat.completions.create(\n",
                "            model=CLOUD_MODEL_NAME,\n",
                "            messages=[\n",
                "                {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ç”¨æˆ·çš„è‹±æ–‡è¾“å…¥ç›´æ¥ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚\"},\n",
                "                {\"role\": \"user\", \"content\": text},\n",
                "            ],\n",
                "            stream=False\n",
                "        )\n",
                "        return response.choices[0].message.content.strip()\n",
                "    except Exception as e:\n",
                "        print(f\"âŒ ç¿»è¯‘å‡ºé”™: {e}\")\n",
                "        return f\"ç¿»è¯‘å¤±è´¥: {str(e)} (å¯èƒ½æ˜¯ API Key æœªé…ç½®)\"\n",
                "\n",
                "        return response.choices[0].message.content.strip()\n",
                "    except Exception as e:\n",
                "        print(f\"âŒ ç¿»è¯‘å‡ºé”™: {e}\")\n",
                "        return f\"ç¿»è¯‘å¤±è´¥: {str(e)} (å¯èƒ½æ˜¯ API Key æœªé…ç½®)\"\n",
                "\n",
                "# Pydantic Model for API\n",
                "class TranslationRequest(BaseModel):\n",
                "    text: str\n",
                "\n",
                "class TTSRequest(BaseModel):\n",
                "    text: str\n",
                "\n",
                "# ==========================================\n",
                "# ğŸš¦ Routes\n",
                "# ==========================================\n",
                "\n",
                "@app.get(\"/\", response_class=HTMLResponse)\n",
                "def home():\n",
                "    \"\"\"Serve the frontend HTML\"\"\"\n",
                "    return pathlib.Path(\"lesson26.html\").read_text(encoding=\"utf-8\")\n",
                "\n",
                "@app.get(\"/qrcode\")\n",
                "def get_qr_image():\n",
                "    ip = get_local_ip()\n",
                "    url = f\"http://{ip}:8000\"\n",
                "    qr = qrcode.QRCode(box_size=10, border=4)\n",
                "    qr.add_data(url)\n",
                "    qr.make(fit=True)\n",
                "    img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
                "    buf = io.BytesIO()\n",
                "    img.save(buf, format=\"PNG\")\n",
                "    buf.seek(0)\n",
                "    return Response(content=buf.getvalue(), media_type=\"image/png\")\n",
                "\n",
                "@app.post(\"/upload\")\n",
                "async def upload_image(file: UploadFile = File(...)):\n",
                "    \"\"\"\n",
                "    Step 1: è§†è§‰è¯†åˆ« (Vision Only)\n",
                "    æ¥æ”¶å›¾ç‰‡ -> Florence-2 ç”Ÿæˆè‹±æ–‡æè¿° -> è¿”å›è‹±æ–‡\n",
                "    \"\"\"\n",
                "    global model, processor\n",
                "    \n",
                "    if not model or not processor:\n",
                "        return {\"error\": \"Model not loaded.\"}\n",
                "\n",
                "    try:\n",
                "        contents = await file.read()\n",
                "        image = Image.open(io.BytesIO(contents))\n",
                "        if image.mode != \"RGB\":\n",
                "            image = image.convert(\"RGB\")\n",
                "        \n",
                "        # æ„é€ æç¤ºè¯ task\n",
                "        prompt = \"<MORE_DETAILED_CAPTION>\"\n",
                "        \n",
                "        # æ‰“å°æ—¥å¿—\n",
                "        print(f\"\\nğŸ“¸ æ”¶åˆ°å›¾ç‰‡: {file.filename}\")\n",
                "        \n",
                "        # è®¡æ—¶å¼€å§‹\n",
                "        start_time = time.time()\n",
                "        \n",
                "        # 1. æœ¬åœ°è§†è§‰æ¨ç† (Florence-2)\n",
                "        inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
                "        generated_ids = model.generate(\n",
                "            input_ids=inputs[\"input_ids\"],\n",
                "            pixel_values=inputs[\"pixel_values\"],\n",
                "            max_new_tokens=1024,\n",
                "            do_sample=False,\n",
                "            num_beams=3,\n",
                "        )\n",
                "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
                "        parsed_answer = processor.post_process_generation(\n",
                "            generated_text, \n",
                "            task=prompt, \n",
                "            image_size=(image.width, image.height)\n",
                "        )\n",
                "        caption_en = parsed_answer[prompt]\n",
                "        \n",
                "        # è®¡æ—¶ç»“æŸ\n",
                "        end_time = time.time()\n",
                "        cost_time = round(end_time - start_time, 2)\n",
                "        \n",
                "        # æ‰“å°æ—¥å¿—\n",
                "        print(f\"â±ï¸ è§†è§‰è€—æ—¶: {cost_time}s\")\n",
                "        print(f\"ğŸ¤– EN: {caption_en}\")\n",
                "        \n",
                "        return {\n",
                "            \"label\": caption_en,     # å…¼å®¹æ—§é€»è¾‘ï¼Œå‰ç«¯å¦‚æœæ˜¯æ—§ç‰ˆä¹Ÿä¼šç›´æ¥æ˜¾ç¤ºè‹±æ–‡\n",
                "            \"caption_en\": caption_en, # æ˜¾å¼å­—æ®µ\n",
                "            \"cost_time\": cost_time\n",
                "        }\n",
                "    except Exception as e:\n",
                "        return {\"error\": str(e)}\n",
                "\n",
                "@app.post(\"/translate\")\n",
                "async def translate_endpoint(request: TranslationRequest):\n",
                "    \"\"\"\n",
                "    Step 2: äº‘ç«¯ç¿»è¯‘ (Language Only)\n",
                "    æ¥æ”¶è‹±æ–‡ -> è°ƒç”¨ API -> è¿”å›ä¸­æ–‡\n",
                "    \"\"\"\n",
                "    print(f\"â˜ï¸ æ”¶åˆ°ç¿»è¯‘è¯·æ±‚: {request.text[:50]}...\")\n",
                "    start_time = time.time()\n",
                "    \n",
                "    caption_zh = translate_text(request.text)\n",
                "    \n",
                "    end_time = time.time()\n",
                "    cost_time = round(end_time - start_time, 2)\n",
                "    \n",
                "    print(f\"ğŸ‡¨ğŸ‡³ ZH: {caption_zh}\")\n",
                "    print(f\"â±ï¸ ç¿»è¯‘è€—æ—¶: {cost_time}s\")\n",
                "    \n",
                "    return {\n",
                "        \"caption_zh\": caption_zh,\n",
                "        \"cost_time\": cost_time\n",
                "    }\n",
                "\n",
                "@app.post(\"/speak\")\n",
                "async def speak_endpoint(request: TTSRequest):\n",
                "    \"\"\"\n",
                "    Step 3: æ–‡æœ¬è½¬è¯­éŸ³ (TTS)\n",
                "    æ¥æ”¶ä¸­æ–‡ -> è°ƒç”¨ SiliconFlow API -> è¿”å› MP3 éŸ³é¢‘æµ\n",
                "    \"\"\"\n",
                "    print(f\"ğŸ”ˆ æ”¶åˆ° TTS è¯·æ±‚: {request.text[:50]}...\")\n",
                "    \n",
                "    # å°è¯•å¤šç§æ–¹å¼è·å– Key\n",
                "    api_key = SILICONFLOW_API_KEY or OPENAI_API_KEY\n",
                "    client = OpenAI(api_key=api_key, base_url=SILICONFLOW_BASE_URL)\n",
                "\n",
                "    def generate_audio():\n",
                "        with client.audio.speech.with_streaming_response.create(\n",
                "            model=\"FunAudioLLM/CosyVoice2-0.5B\", \n",
                "            voice=\"FunAudioLLM/CosyVoice2-0.5B:anna\", # éŸ³è‰²\n",
                "            input=request.text, \n",
                "            response_format=\"mp3\"\n",
                "        ) as response:\n",
                "            for chunk in response.iter_bytes():\n",
                "                yield chunk\n",
                "\n",
                "    return StreamingResponse(generate_audio(), media_type=\"audio/mpeg\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    ip = get_local_ip()\n",
                "    port = 8000\n",
                "    url = f\"http://{ip}:{port}/docs\"\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*50)\n",
                "    print(f\"ğŸš€ Lesson 26 AI Vision Translator å¯åŠ¨ä¸­...\")\n",
                "    print(f\"Running on: {url}\")\n",
                "    print(\"=\"*50)\n",
                "    \n",
                "    # æ‰“å°äºŒç»´ç ä¾›æ‰«æ\n",
                "    try:\n",
                "        qr = qrcode.QRCode()\n",
                "        qr.add_data(url)\n",
                "        qr.print_ascii(invert=True)\n",
                "        print(f\"\\nğŸ“± æ‰‹æœºæ‰«ç ä½“éªŒ: {url}\")\n",
                "    except:\n",
                "        pass\n",
                "    \n",
                "    print(\"\\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡\")\n",
                "    \n",
                "    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python app_v2.py"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}