# **风险迫在眉睫：2025年10月至11月人工智能进展及其新兴社会风险分析**

## 执行摘要

2025年10月末至11月初，人工智能领域经历了一系列技术突破，标志着一个关键的“临界点”：即技术能力已明确超越了现有的社会保障与治理框架。本报告基于对近期技术报告和新闻事件的深入分析，旨在全面评估这些进展，并重点研究其对人类社会（尤其是内容生态、人身安全和个人隐私）的深远影响。

分析揭示了五大关键趋势：

1. **生成式视频的超真实化与武器化：** 以OpenAI的Sora 2和Google的Veo 3.1为代表的新一代视频模型，在物理真实性、音频同步和可控性方面实现了飞跃，但也因此成为了制造虚假信息和身份欺诈的完美工具。  
2. **具身智能的市场拐点与系统性风险：** 以特斯拉Optimus为代表的人形机器人正从原型转向大规模商业化，预示着一场深刻的经济结构转型，同时也带来了关于劳动力替代、物理安全和伦理问责的严峻挑战。  
3. **神经解码的伦理前沿：** “思维字幕”（Mind Captioning）技术首次实现了从大脑活动中高精度解码非语言的视觉语义内容，使“精神隐私”从一个抽象的哲学概念变成了紧迫的现实治理问题。  
4. **“智能体”AI的范式转变：** Kimi K2 Thinking和Kosmos等“思考智能体”的出现，标志着AI从“生成内容”转向“执行任务”和“自主发现”，这种长时程、多步骤的自主性构成了全新的安全风险。  
5. **治理框架的滞后与应对：** 面对上述挑战，一方面是现有安全措施（如水印）的迅速失效，另一方面，新的治理理念（如“策略卡”）和地缘政治战略（如乌镇峰会所展示的）正在形成。

本报告的核心结论是：这五大趋势并非孤立发展，而是**相互催化**，共同将我们推向了一个**系统性的“临界点”**。新型的**“智能体”AI**（趋势4）是这场变革的引擎，它不仅为超真实视频（趋势1）的武器化提供了“大脑”，更驱动着AI进入物理世界（趋势2：具身智能）和解码精神世界（趋势3：神经解码）。这场多维度的技术爆炸，其速度已让现有的治理框架（趋势5）显得捉襟见肘甚至**彻底失效**。

无论是“AI产生内容，算法分发流量”的信任黑洞，还是“先发布，后治理”的自主性风险，都暴露了**“事后补救”式治理思路的彻底失败**。面对这场由自主智能体驱动的、多维度的系统性危机，我们必须从根本上转变思路，转向**嵌入式、实时、可验证的治理框架**（如“策略卡”）和对**关键行为（如算法放大效应）的直接问责**，以重建信任与安全。

---

## 第一部分 合成内容危机：评估Sora 2与Veo 3.1的影响

本部分将重点分析我们所关切的生成式视频技术滥用问题。2025年秋季发布的Sora 2和Veo 3.1不仅是技术迭代，它们从根本上改变了虚假内容制造的成本、速度和逼真度，对短视频平台和内容创作者生态造成了直接冲击。

### **1.1 超真实与可控性的新阈值**

近期视频模型的迭代，其核心研发方向就是为了消除早期模型中可被人类轻易识别的“AI瑕疵”。

* **OpenAI Sora 2：** OpenAI于2025年9月30日发布的Sora 2系统卡显示，该模型（同时作为独立的iOS应用和API发布）实现了“更准确的物理模拟”、“更清晰的真实感”、“同步音频”和“增强的可控性” ³。Sora 2提供了两种模式：用于快速迭代的sora-2和用于“电影级”质量的sora-2-pro ⁴。用户的上手评测证实了其物理和音视频同步的“惊人”质量，例如能够正确模拟物体入水的水花飞溅，或是在ASMR（自发性知觉经络反应）视频中精准匹配按键声和呼吸声的时间 ⁵。  
* **Google Veo 3.1：** Google于10月15日发布的Veo 3.1，同样在API中提供了预览 ⁸。其技术文档强调了“更丰富的原生音频”（包括自然的对话）、通过“对电影风格的更深刻理解”实现的“更强的叙事控制力”，以及“卓越的音视频质量” ⁸。

这些技术进步的直接后果是，过去作为被动安全屏障的“恐怖谷”（如物理效果诡异、音画不同步、角色在镜头间发生“变形”）几乎被填平。模型“解决”这些问题的过程，就是它们成为更完美欺诈工具的过程。两大巨头在音视频真实感上的激烈竞争 ⁷，正在无限加速这一风险的到来。

### **1.2 “Cameo”效应：个性化深度伪造的规模化**

如果说模型的真实感是技术基础，那么Sora 2应用中的“Cameo”（客串）功能，则是将这种威胁“产品化”并推向数亿消费者的“最后一公里”。

“Cameo”是一项“杰出”且“革命性”的功能 ⁵。它允许用户上传一段简短的个人视频进行“验证”，随后系统就能“克隆”该用户的外貌和**声音**，并将其“注入”到任何AI生成的场景中 ⁶。

OpenAI将此功能描述为“*基于同意*的个人深度伪造” ¹⁵，Sora 2的系统卡也声称用户“通过Sora的肖像控制Cameo功能表示同意” ³。然而，这套“同意机制”存在一个致命的逻辑漏洞：它验证的仅仅是**上传者拥有（或窃取了）某段包含特定人物的视频**，而**非**上传者获得了视频中人物的**合法授权**来克隆其生物特征。

这种设计将一个高技术门槛的犯罪行为（如制造深度伪造视频 ¹⁶），打包成了一个用户友好的“一键混剪”按钮 ⁶。它事实上创造了一个工作流，用于大规模生产高保真的、个性化的深度伪造内容，导致发布后短时间内，大量包含著名IP角色的伪造视频（如皮卡丘等）迅速在社交媒体上传播，引发了全球版权和肖像权的激烈讨论 ¹⁷。“Cameo”功能将深度伪造行为“社交化”和“娱乐化”，使其潜在危害性呈指数级增长。

### **1.3 “AI垃圾”的洪流：算法放大与生态系统衰退**

Sora 2和Veo 3.1等工具的发布，在社交媒体上引发了一场“合成内容的突然的、戏剧性的激增” ¹⁸。这正是用户所担忧的“劣质内容”。行业观察者将其称为“AI Slop”（AI垃圾） ¹：即专为“压垮现有数字护栏” ¹⁸ 和“渗入用户订阅流” ¹ 而设计的、低成本、高参与度的内容。这种内容的泛滥，正在创造一个“高噪音、低信任的空间”和一种“低水平的偏执感” ¹。

这一现象并非孤立发生，而是由一个破坏性的**算法共生系统**驱动的，该系统完美印证了我们对于“算法放大劣质内容”的担忧：

1. **供给方（AI公司）：** Sora 2和Veo 3.1以近乎为零的边际成本，提供了合成内容的**无限供给** ¹⁸。  
2. **需求方（平台算法）：** 社交媒体的推荐算法是“人工智能驱动的内容策展系统”，其唯一目标是“过滤和放大内容以最大化用户参与度” ²。这些算法为AI垃圾提供了**无限的自动化需求**，因为它们奖励的是“参与度”，而非“真实性”或“原创性”。  
3. **平台的动机：** AI公司需要这个“飞轮”。它们将Sora 2和Veo 3作为消费级应用推出，是为了获取“主流用户的使用” ¹，这能“同时改进他们的产品” ¹——换言之，平台上的所有用户互动，都在为AI公司免费提供下一代模型所需的、规模庞大的训练数据。  
4. **算法的偏好：** 算法早已被证明会奖励“分裂性内容” ¹。当AI可以无限量制造此类内容时，算法只会“加剧这种动态” ¹，创造一个“更加两极分化的回音室” ¹。

这是一个三方共赢的闭环：AI公司获得训练数据，平台获得廉价且高粘性的内容，而恶意行为者则获得了完美的掩护。唯一的输家是公众和人类创作者。

### **1.4 技术保障的溃败：以“水印清除”为例**

面对AI内容的泛滥，整个行业向监管者和公众提供的核心技术安全承诺，就是“水印” ²⁰。Sora 2在发布时，其视频也确实带有一个可见的水印 ²¹。

然而，这一承诺在发布后数天内即被证伪，完美印证了我们对“抹去水印”的担忧：

* 首先，一个“Sora水印去除器”的地下产业迅速形成 ²¹。  
* 其次，更具毁灭性的是，来自滑铁卢大学（University of Waterloo）的学术研究（即“UnMarker”工具）“暴露了（水印技术的）一个系统性漏洞” ²⁰。该工具的突破之处在于，它**无需了解水印算法的内部结构**即可实现清除。  
* 该研究的结论是，将水印作为抵御深度伪造的方法“很可能走错了方向”，并且“不是一个可行的盾牌” ²⁰。

这一事实意味着，**整个生成式媒体领域面向公众的技术安全战略，在发布时就已经被证明是失败的。**

这个失败制造了一个巨大的“治理缺口”：政策制定者被说服去依赖一个已被证明无效的技术假设 ²⁰。这迫使我们回到一个更困难的问题：即依赖“内容不可知”的AI检测工具（这在技术上难度极高 ²¹），或是转向“真实性溯源”（即验证*真实*内容，而非检测*虚假*内容），而后者目前同样没有可规模化的解决方案。

### **1.5 武器化、创作者冲击与社交媒体的“丧钟”**

如前文所述，技术的滥用并非理论上的可能，而是已经发生的现实。

* **武器化：** 新闻调查机构NewsGuard的分析发现，在测试中，Sora 2在**88%的时间里**（20次提示中有16次）会“产生推进可证伪主张的逼真视频” ²²。这些虚假内容包括“源于俄罗斯的虚假信息行动”、伪造的新闻报道（例如“摩尔多瓦选举官员销毁亲俄选票”）以及损害品牌的虚假声明 ²²。这种风险建立在已有事实之上，例如2024年Arup公司因深度伪造视频电话会议而被诈骗2550万美元的案件 ¹⁶。  
* **对人类创作者的冲击：** 我们所担忧的“对人类创作者的负面冲击”是这场危机的核心。“AI垃圾” ¹ 正在开启一场“竞次”（race to the bottom），即“内容质量的探底” ¹。人类创作者的核心价值在于“真实性和真实的关系” ²⁴，但他们现在被迫在经济上与一个**供给无限、成本为零、且为算法量身定制**的合成媒体进行竞争 ¹⁹。这从根本上贬低了人类原创努力的价值，威胁着整个“创作者经济” ²⁴。

当平台算法无法（或者更准确地说，**不愿**）区分一个高投入的人类原创视频和一个10秒钟生成的“AI垃圾”，并且只奖励后者所带来的即时参与度时，人类创作的经济激励就崩溃了。这导向了批评者们所称的“社交媒体的潜在‘丧钟’” ¹。

平台方在追求AI训练数据“飞轮” ¹ 的过程中，正在亲手摧毁它们自身的核心价值——“人际联系” ¹。如果一切都可能是假的，社交媒体的“意义”也就消失了，人们最终只会“退回到物理上可证明的现实中去” ¹。

#### **表1：Sora 2 vs. Veo 3.1 功能与系统性风险对比**

| 模型 | 关键技术能力 | 主要访问平台 | 宣传的“功能” | 赋能的系统性风险 |
| :---- | :---- | :---- | :---- | :---- |
| **OpenAI Sora 2** | sora-2-pro ⁴ 同步音频与物理模拟 ³ | iOS 消费级应用 ³ | “Cameo” (客串) ¹⁵ | “个人深度伪造的产品化； 规模化的非自愿身份克隆。” |
| **Google Veo 3.1** | gemini-api ⁸ 电影级控制与原生音频 ⁸ | 开发者 API ⁸ | “Ingredients to video” (引导生成) ⁸ | “用于复杂虚假叙事的高保真、 跨场景角色一致性。” |

---

## 第二部分 具身智能体：人形AI的物理、经济与伦理风险

“具身智能”（Embodied AI）是AI技术发展的另一条关键路径，它旨在让AI走出屏幕，进入物理世界。我们对此“潜在问题”的关切，集中在以特斯拉Optimus为代表的人形机器人所带来的系统性风险上。

### **2.1 从工厂到未来：特斯拉Optimus与市场拐点**

特斯拉的目标是打造一个“通用的、双足的、自主的人形机器人” ²⁶，它将利用特斯拉从“全自动驾驶”（FSD）中磨练出来的“AI实力” ²⁷。特斯拉CEO埃隆·马斯克的愿景极其宏大：Optimus可能占“特斯拉未来价值的80%” ²⁸，并将“重新定义工作的本质” ²⁹。预计在2026年亮相的第三代（Gen 3）模型，目标是实现“手术级的精度” ²⁷。

这并非特斯拉的独角戏，而是整个行业的“拐点”（inflection point） ³⁰。关键驱动力在于AI（用于学习任务的大型行为模型LBMs，用于交流的大型语言模型LLMs）和可规模化的硬件（更轻的执行器、支持数小时工作的电池）的融合 ³⁰。

分析机构Yole Group的报告指出，这个市场将迎来“指数级增长”，预计市场规模将从**2030年的60亿美元增长到2035年的510亿美元** ³⁰。更关键的数字是出货量，预计到**2035年将超过200万台** ³⁰。

这场经济变革的核心“潜在问题”，隐藏在一个关键指标中：人形机器人的平均销售价格（ASP）预计将从2025年的75,000美元，**下降到2035年的25,000美元** ³⁰。

这个价格的转变意义重大：一台售价7.5万美元的机器人 ³⁰，是与人类工人竞争的昂贵资本；而一台售价2.5万美元 ³⁰、可以7x24小时工作、不会受伤、并通过“蜂群”更新来学习新技能的机器人，它不再是“竞争者”，而是“**替代品**”。马斯克“终结贫困” ³¹ 和创造“可持续富足” ²⁹ 的乌托邦式框架，其背后是人类历史上可能最迅速、最彻底的劳动力置换。

### **2.2 具身智能 (EAI) 风险分类**

来自学术界（如arXiv:2509.00117）的分析，为我们提供了一个评估具身智能风险的全面框架。具身智能“比纯虚拟的AI系统更容易造成直接的物理伤害” ³²。

* **物理风险：** 最直接的风险。包括AI在执行任务时造成的直接物理伤害 ³⁴，以及通过“越狱”其底层的LLM来恶意使用机器人 ³²。  
* **信息风险：** 具身智能体是移动的、全方位的监控平台。一个用于“老年护理”的机器人 ³²，同时也是一个部署在私人住宅内的、持续不断的数据采集设备，这带来了严重的“隐私侵犯” ³²。  
* **经济风险：** 如前所述，“广泛的劳动力替代” ³² 是最大的风险。这不仅会导致“社会经济不平等”加剧，更会导致“权力集中” ³²——即那些拥有和运营机器人舰队的超级公司将获得前所未有的经济和政治权力。  
* **社会风险：** 包括“偏见和歧视”（例如机器人在不同种族或性别的用户面前表现不同） ³²；“缺乏问责和责任”（当Optimus造成事故时，谁来负责？是特斯拉、AI、还是所有者？） ³²；以及“不健康或危险的人机关系”（例如人类对护理机器人产生情感依赖，但机器的记忆随时可能被重置） ³²。更深远的“变革性影响”甚至包括AI驱动的威权主义，即机器人成为“物理威胁”和大规模监视的执行工具 ³⁵。

### **2.3 自主性困境：一个根本性的矛盾**

具身智能的核心“潜在问题”，在于其商业目标与安全要求之间存在一个无法调和的根本性矛盾。

一方面，特斯拉的**核心目标**是实现“通用的...**自主的**人形机器人” ²⁹。商业价值（即替代人类劳动力）完全取决于其“自主性”的程度。

另一方面，来自AI安全界的明确结论（如arXiv:2502.02649）是：“**风险与系统的自主性成正比**” ³⁷。“用户让渡给AI智能体的控制权越多，（系统）对人造成的风险就越大” ³⁷。该论文的标题甚至是一个激进的结论：“不应开发完全自主的AI智能体” ³⁸。

这不是一个可以通过技术优化来解决的张力，这是一个**根本性的矛盾**。整个行业正在斥资数百亿，竞相奔向一个安全界明确警告“不应被开发”的未来。

#### **表2：具身智能 (EAI) 风险分类框架 (改编自 arXiv:2509.00117)**

| 风险领域 | 描述 | 具身智能示例 (关联Optimus) |
| :---- | :---- | :---- |
| **物理风险** | 来自自主行动的直接物理伤害。 | Optimus ²⁷ 的“手术级精度”发生误判， 伤害操作员或损坏昂贵设备 ³⁴。 |
| **信息风险** | 通过移动传感器侵犯隐私。 | Optimus ²⁹ 在家庭或工厂中运行时， 持续收集私人或专有数据 ³²。 |
| **经济风险** | 大规模、结构性的劳动力替代。 | 200万台 ³⁰ 定价2.5万美元 ³⁰ 的机器人， 全面替代制造业、物流业和护理业岗位 ³²。 |
| **社会风险** | 问责真空与社会结构重塑。 | “自主的”Optimus ²⁶ 造成数百万美元的损失， 责任在特斯拉、AI模型和所有者之间无法界定 ³²。 |

---

## 第三部分 内部边界：“思维字幕”与精神隐私之战

如果说具身智能的风险在于AI对“外部物理世界”的侵犯，那么神经AI的突破则指向了对“内部精神世界”的解码。我们所关切的“思维字幕”（Mind Captioning）技术，正是这一领域的伦理前沿。

### **3.1 技术突破：解码语义思想**

2025年11月，发表于《科学进展》(Science Advances) 的一项由Horikawa (2025) 主导的突破性研究 ³⁶，展示了“思维字幕”技术。

* **技术原理：** 该系统采用一个两阶段AI模型。首先，使用线性模型从功能性磁共振成像（fMRI）捕捉的大脑活动中解码“语义特征”；其次，使用一个掩码语言模型（masked language model）将这些解码后的特征，转换成连贯的、描述性的文本 ³⁶。  
* **核心能力：** 系统能够“读取……大脑的反应” ³⁹。当参与者观看视频时，它描述画面的准确率近**58%**；更令人瞩目的是，当参与者**回忆**视频时（即解码纯粹的记忆和想象），准确率仍高达**40%** ³⁹。  
* **关键发现：** 该系统在生成文本时，**并不依赖**大脑中传统的“语言中枢” ³⁹。这有力地表明，AI解码的不是语言本身，而是语言背后的**意义**，即“结构化的视觉语义” ³⁶。

### **3.2 双重用途：“为失语者发声” vs. “窃听私人思想”**

与所有颠覆性技术一样，“思维字幕”具有极端的双重用途：

* **积极潜力：** 其人道主义潜力是巨大的。它可以“为无法发声的人提供新的声音” ⁴¹。对于那些因失语症、肌萎缩侧索硬化症（ALS）或瘫痪而“能够思考但无法言说”的人来说，该系统可以充当“精神表征和语言之间的解释性接口”，提供一条“替代性沟通途径” ³⁶。  
* **潜在风险：** 研究者们自己也警告说，保护“**精神隐私**” (mental privacy) 将变得至关重要 ⁴¹。风险在于“对私人思想的非自愿解释” ⁴¹，或“窃听私人语言思想” ⁴³。更进一步的风险是，将这种“神经数据”（neurodata）与其他个人信息相结合，构建“颗粒度极高且敏感的用户画像”，用于“侵入性或剥削性用途”（例如行为广告） ⁴⁴。

### **3.3 定义“潜在问题”：语义陷阱**

在讨论伦理问题时，该研究的主要作者Horikawa博士**特意澄清**：这在“反乌托邦意义上”**并非“读心术”** (mind reading) ³⁹。他声称，该方法“**不解码私人思想**”，而是“解释大脑的语义特征” ³⁹。

然而，这正是该技术最核心的“潜在问题”所在：**研究者所做的“语义特征”和“私人思想”之间的技术区分，在法律、伦理和实践上是毫无意义的。**

这是一个“语义陷阱”：

1. 该系统自己的输出——例如“一个人在山脊上跳过一个很深的瀑布” ³⁹——在任何功能定义上，*就是*一个私人思想。  
2. 该系统能够解码“**被回忆的记忆**” ³⁹，这无可辩驳地就是“读心术”。  
3. 这种技术使得长期以来关于“神经权”（neurorights）的抽象辩论 ⁴⁶，突然变成了一个**迫在眉睫的具体威胁**。

目前，唯一的安全屏障是该技术依赖于庞大、昂贵且非便携的**fMRI（功能性磁共振成像）机器** ³⁹。但研究者们在论文中明确展望的未来，是更小的、可植入或“可穿戴的脑机AI接口” ⁴¹。一旦硬件小型化，这道最后的物理屏障也将消失。

---

## 第四部分 自主智能体：新架构与治理缺口

如果说前三部分描述的是AI带来的具体威胁（虚假内容、物理伤害、隐私侵犯），那么第四部分将分析驱动这些威胁的底层范式转变——AI正从“生成式”转向“智能体式”（Agentic）。

### **4.1 “思考智能体”的登场：Kimi K2 与 Kosmos**

2025年11月，两篇论文的发布标志着“智能体AI”范式的成熟：

* **Kosmos：自主科学发现：** 一篇名为“Kosmos：一个用于自主发现的AI科学家”的论文 ⁴⁸ 展示了一个专为“长时程推理” ⁵¹ 而设计的系统。它通过运行迭代“循环” ⁴⁹，利用一个“结构化世界模型”来协调一个“数据分析智能体”和一个“文献搜索智能体” ⁴⁸。在一次长达12小时的运行中，Kosmos可以执行**42,000行代码**并阅读**1,500篇论文** ⁴⁸。其成就惊人：它**独立复现了（未发表的）研究成果**，并**做出了四项新颖的科学贡献** ⁴⁸。合作的科学家估计，Kosmos单次运行的成果平均相当于他们“6个月的研究时间” ⁴⁸。  
* **Kimi K2 Thinking：自主工具调用：** 与此同时，中国月之暗面（Moonshot AI）发布了开源的“思考智能体”Kimi K2 Thinking ⁵²。这是一个拥有1万亿参数的混合专家（MoE）模型（激活参数为320亿） ⁵²。其核心能力不再是“生成”，而是“**工具使用**”。它可以在没有人类干预的情况下，**连续执行200-300个顺序工具调用** ⁵²，在多个智能体基准测试中击败了GPT-5和Sonnet 4.5 ⁵⁵。

这两项进展标志着一个根本性的范式转变：AI正从“会说话的AI”（生成式）转向“**会做事的AI**”（智能体式）。这些智能体正是驱动前述风险的核心“大脑”——一个可以执行200步来策划虚假信息运动的“Sora智能体”，或是一个可以执行300步来完成复杂任务的“Optimus智能体”。

### **4.2 控制框架：“策略卡”作为机器可读的治理**

在智能体能力飞跃的同时，一个旨在解决其治理难题的工程框架也随之出现。10月发布的“策略卡（Policy Cards）：面向自主AI智能体的机器可读运行时治理” ⁵⁷，是对智能体风险的直接技术回应。

* **它解决的问题：** 自主智能体（如Kimi K2）需要在“受法律、伦理和安全关键程序约束”的环境中运行 ⁵⁷。但传统的治理文件（如模型卡、PDF格式的法规）并非“机器可读”，也无法在“运行时”（runtime）被强制执行 ⁵⁹。  
* **解决方案：** “策略卡”是一种“**机器可读的、部署层标准**” ⁵⁹。它是一个与智能体“坐”在一起的文件，明确告诉智能体“**必须做什么和不能做什么**” ⁵⁹。它编码了“允许/拒绝规则、义务（和）证据要求”，并将它们映射到法律框架（如欧盟AI法案或NIST RMF） ⁵⁷。这使得“可验证的合规性”和“可问责的自主性”成为可能 ⁵⁷。

在第一部分（Sora 2）中，我们看到“事后”的水印治理是如何彻底失败的 ²⁰。在第二部分（Optimus）中，我们看到“完全自主”是风险的核心来源 ³⁷。

“策略卡”提供了一条应对路径：它不是在AI犯错后去检测它（如水印），而是在AI行动*之前*就为其设定刚性约束。这是一个“针和线”的解决方案，它将“治理”（线）直接缝合到了智能体执行任务的“引擎”（针）中，确保了在无人监督的“运行时”也能实现治理。

#### **表3：从生成式到智能体式的AI范式转变与治理挑战**

| 模型类型 | 范例 | 主要功能 | 关键能力 (指标) | 治理挑战 |
| :---- | :---- | :---- | :---- | :---- |
| **生成式 LLM** | GPT-4 | 回答提示 | 文本/图像生成 | 幻觉、偏见、版权 |
| **智能体模型** | Kimi K2 Thinking ⁵³ | 执行任务 | 顺序工具使用 (200-300次) ⁵³ | 意外后果、运行时安全 |
| **自主系统** | Kosmos ⁴⁸ | 实现目标 | 长时程推理 (12小时运行) ⁴⁸ | 目标错位、自主性问责 |

---

## 第五部分 战略应用与全球背景

在深入探讨AI风险的同时，我们也必须看到AI在解决人类最重大挑战方面的巨大潜力，以及全球不同参与者在这一领域的战略布局。

### **5.1 高影响力的AI：加速聚变与保护自然**

与第一部分中“AI垃圾” ¹ 形成鲜明对比的是，同一家公司（Google DeepMind）在几乎同一时间，展示了AI在解决复杂、高资本、非营利性问题上的应用。

* **加速核聚变：** Google DeepMind宣布与联邦聚变系统（CFS）合作 ⁶²。他们利用名为“TORAX”的开源等离子体模拟器——它“快速、准确（且）可微分” ⁶⁴——在SPARC托卡马克装置**开机之前**，就运行了“数百万次虚拟实验”来优化等离子体控制 ⁶²。这极大地缩短了实现商业聚变能源的时间线。  
* **保护生物圈：** Google的“AI for Nature”（AI促进自然）计划 ⁶⁵ 展示了另外两项突破：一是“ForestCast”，一个利用深度学习**预测**（而非仅仅是监测）森林砍伐风险的模型 ⁶⁶；二是“Perch 2.0”，一个利用生物声学（鸟鸣等）来大规模绘制和跟踪物种分布的AI模型 ⁶⁶。

这揭示了AI在文明尺度上的深刻的“双重用途”属性：当Sora 2被用于制造“AI垃圾”时，TORAX正在模拟核聚变。这凸显了AI在药物发现 ⁷⁰、新材料和生命科学等基础科学领域不可替代的积极价值。

### **5.2 乌镇峰会：中国的“AI共生”战略**

2025年11月7日至9日举行的世界互联网大会（WIC）乌镇峰会 ⁷²，则揭示了另一种截然不同的AI发展路径。

* **峰会主题：** 本届峰会的主题是“AI共生” ⁷³。与会的全球技术领袖指出，峰会的焦点不在于“炒作”（hype），而在于**“部署”、“合规”和“算力”** ⁷⁴。  
* **战略重点：** 中国的战略是推动AI与“实体产业融合” ⁷³，例如将“AI驱动的创新”用于网络安全和关键基础设施的“量子安全” ⁷³。峰会明确传达出“随着AI使用率和普及率的提高，中国加强了治理” ⁷⁵ 这一信号。  
* **关键技术：** 峰会的核心议题包括具身智能 ⁷⁶、阿里巴巴的Qwen（通义千问）大模型 ⁷² 以及“计算基础设施的稳步升级” ⁷⁶。

乌镇峰会所展现的AI战略，与第一部分所述的乱象形成了鲜明对比：如果说Sora 2所代表的美国路线是“自下而上”的、以消费者应用驱动的、混乱的市场行为；那么乌镇峰会所代表的中国路线则是“自上而下”的、以国家战略结盟的、聚焦于工业、基础设施和前置治理的产业行为。

---

## 第六部分 结论分析与战略建议

2025年10月至11月这一短暂的时间窗口，清晰地揭示了AI风险的系统性加速，技术能力已在多个维度上突破了现有治理框架。

### **6.1 新兴风险综合研判**

* **核心治理缺口：** 最大的失败在于行业和监管依赖“事后”的技术补救措施（如水印），而这些措施已被证明是“不可行”的 ²⁰。这个失败，与那些*激励*“AI垃圾”传播的平台算法 ² 相结合，创造了一个“高噪音、低信任”的数字环境，其主要受害者是人类创作者和公众信任。  
* **迫在眉睫的危机：** 这场“真实性危机”（第一部分）与具身智能带来的“自主性危机”（第二部分）以及神经解码带来的“隐私危机”（第三部分）并行发生。而所有这些危机的背后，都是由新型“智能体”范式（第四部分）所驱动的。

### **6.2 面向利益相关者的战略建议**

**致政策制定者与监管机构：**

1. **放弃失败的保障措施：** 立即停止将“水印”作为解决AI生成内容问题的主要或可行方案。政策必须从“检测虚假”转向“**认证真实**”（Provenance），并建立**平台问责制**。  
2. **监管算法放大效应：** 法律和经济责任的主体，应从难以追溯的内容“生成者”转向内容的“**放大者**”（即社交媒体平台 ²）。平台必须对其算法放大虚假信息和“AI垃圾” ²² 的行为承担法律责任。  
3. **强制推行“运行时治理”：** 对于“高风险”自主系统（参照欧盟AI法案 ⁵⁹），包括具身智能体（如Optimus）和关键基础设施智能体（如TORAX），应强制要求采用“策略卡” ⁵⁹ 等机器可读的治理框架，作为其部署的先决条件。  
4. **立即确立“神经权”：** 必须在脑机接口技术（BCI）变得可穿戴化和规模化*之前*，迅速行动，为“精神隐私” ⁴¹ 和神经数据治理 ⁴⁴ 建立法律框架。

**致行业（技术平台与媒体）：**

1. **停止将社会危害视为公关问题：** AI实验室必须停止发布那些安全措施明显不足的产品 ²²，而平台方则必须停止从“AI垃圾”的“飞轮效应”中获利 ¹。  
2. **以“信任”为核心竞争力：** 公众“退回到物理上可证明的现实中去” ¹ 的趋势，是一个巨大的**市场机遇**。媒体公司和创作者平台应投资于**以人类为中心**的算法、严格的人工验证，并将“真实性” ²⁴ 作为其核心价值主张，以区别于合成的“AI垃圾”。  
3. **自愿采用“策略卡”：** 领先的科技公司不应等待监管，而应主动采用“运行时治理” ⁵⁷ 作为行业最佳实践，以建立市场信任并确保“可问责的自主性” ⁵⁹。
#
## 引用的资料

1. When Everything Is Fake, What's the Point of Social Media? | TIME, 访问时间为 2025-11-10， [https://time.com/7326718/sora-2-ai-fake-videos-social-media/](https://time.com/7326718/sora-2-ai-fake-videos-social-media/)  
2. Viral Leadership: Algorithmic Amplification and the Rise of Leadership Fashions - MDPI, 访问时间为 2025-11-10， [https://www.mdpi.com/2076-3387/15/6/202](https://www.mdpi.com/2076-3387/15/6/202)  
3. Sora 2 System Card | OpenAI, 访问时间为 2025-11-10， [https://cdn.openai.com/pdf/50d5973c-c4ff-4c2d-986f-c72b5d0ff069/sora\_2\_system\_card.pdf](https://cdn.openai.com/pdf/50d5973c-c4ff-4c2d-986f-c72b5d0ff069/sora_2_system_card.pdf)  
4. Video generation with Sora - OpenAI API, 访问时间为 2025-11-10， [https://platform.openai.com/docs/guides/video-generation](https://platform.openai.com/docs/guides/video-generation)  
5. Sora 2: What It Is, How It Works, and How To Use It - Krea AI, 访问时间为 2025-11-10， [https://www.krea.ai/articles/sora-2](https://www.krea.ai/articles/sora-2)  
6. Sora 2: Tried It, Floored by Features… but Why Is It Just Meme Clips? : r/CreatorsAI - Reddit, 访问时间为 2025-11-10， [https://www.reddit.com/r/CreatorsAI/comments/1o2crd6/sora\_2\_tried\_it\_floored\_by\_features\_but\_why\_is\_it/](https://www.reddit.com/r/CreatorsAI/comments/1o2crd6/sora_2_tried_it_floored_by_features_but_why_is_it/)  
7. Sora 2 vs Veo 3.1: I tested both AI video generators with 7 audio prompts — here's the winner | Tom's Guide, 访问时间为 2025-11-10， [https://www.tomsguide.com/ai/ai-image-video/sora-2-vs-veo-3-1-i-tested-both-ai-video-generators-with-7-audio-prompts-heres-the-winner](https://www.tomsguide.com/ai/ai-image-video/sora-2-vs-veo-3-1-i-tested-both-ai-video-generators-with-7-audio-prompts-heres-the-winner)  
8. Introducing Veo 3.1 and new creative capabilities in the Gemini API ..., 访问时间为 2025-11-10， [https://developers.googleblog.com/en/introducing-veo-3-1-and-new-creative-capabilities-in-the-gemini-api/](https://developers.googleblog.com/en/introducing-veo-3-1-and-new-creative-capabilities-in-the-gemini-api/)  
9. Veo - Google DeepMind, 访问时间为 2025-11-10， [https://deepmind.google/models/veo/](https://deepmind.google/models/veo/)  
10. Testing OpenAI Sora 2 vs Google Veo 3: There's a clear winner | Mashable, 访问时间为 2025-11-10， [https://mashable.com/article/openai-sora-2-vs-google-veo-3-ai-video](https://mashable.com/article/openai-sora-2-vs-google-veo-3-ai-video)  
11. Introducing Veo 3.1 and advanced capabilities in Flow : r/singularity - Reddit, 访问时间为 2025-11-10， [https://www.reddit.com/r/singularity/comments/1o7fco8/introducing\_veo\_31\_and\_advanced\_capabilities\_in/](https://www.reddit.com/r/singularity/comments/1o7fco8/introducing_veo_31_and_advanced_capabilities_in/)  
12. I test the new Google Veo 3.1 vs. OpenAI's Sora 2 : r/aiecosystem - Reddit, 访问时间为 2025-11-10， [https://www.reddit.com/r/aiecosystem/comments/1o81uyy/i\_test\_the\_new\_google\_veo\_31\_vs\_openais\_sora\_2/](https://www.reddit.com/r/aiecosystem/comments/1o81uyy/i_test_the_new_google_veo_31_vs_openais_sora_2/)  
13. Veo 3.1 vs. Sora 2: The Ultimate AI Video Showdown - CrePal Content Center, 访问时间为 2025-11-10， [https://crepal.ai/blog/agent/veo-3-1-vs-sora-2-the-ultimate-ai-video-showdown/](https://crepal.ai/blog/agent/veo-3-1-vs-sora-2-the-ultimate-ai-video-showdown/)  
14. Real or AI? It's Harder Than Ever to Spot AI Videos. These Tips Can Help - CNET, 访问时间为 2025-11-10， [https://www.cnet.com/tech/services-and-software/real-or-ai-its-harder-than-ever-to-spot-ai-videos-these-tips-can-help/](https://www.cnet.com/tech/services-and-software/real-or-ai-its-harder-than-ever-to-spot-ai-videos-these-tips-can-help/)  
15. OpenAI's Sora 2: A New Chapter in Generative Video - Medium, 访问时间为 2025-11-10， [https://medium.com/@itxcrusher/sora-2-deep-dive-capabilities-use-cases-risks-strategy-b718b95ee516](https://medium.com/@itxcrusher/sora-2-deep-dive-capabilities-use-cases-risks-strategy-b718b95ee516)  
16. Detecting dangerous AI is essential in the deepfake era | World Economic Forum, 访问时间为 2025-11-10， [https://www.weforum.org/stories/2025/07/why-detecting-dangerous-ai-is-key-to-keeping-trust-alive/](https://www.weforum.org/stories/2025/07/why-detecting-dangerous-ai-is-key-to-keeping-trust-alive/)  
17. Sora 2 Copyright Issue: Legal Risks and AI Policy Shift, 访问时间为 2025-11-10， [https://ailaw.co.jp/en/blog-en/openai-sora2-cameo-copyright-analysis/](https://ailaw.co.jp/en/blog-en/openai-sora2-cameo-copyright-analysis/)  
18. Fake AI Generated Videos Deluge Social Media: Sora 2 Release - Aragon Research, 访问时间为 2025-11-10， [https://aragonresearch.com/fake-ai-generated-videos/](https://aragonresearch.com/fake-ai-generated-videos/)  
19. Beyond The Hype: How AI Is Quietly Reshaping The Creator Economy - B2B News Network, 访问时间为 2025-11-10， [https://www.b2bnn.com/2025/03/beyond-the-hype-how-ai-is-quietly-reshaping-the-creator-economy/](https://www.b2bnn.com/2025/03/beyond-the-hype-how-ai-is-quietly-reshaping-the-creator-economy/)  
20. Canadian researchers create tool to remove anti-deepfake watermarks from AI content, 访问时间为 2025-11-10， [https://www.ctvnews.ca/sci-tech/article/canadian-researchers-create-tool-to-remove-anti-deepfake-watermarks-from-ai-content/](https://www.ctvnews.ca/sci-tech/article/canadian-researchers-create-tool-to-remove-anti-deepfake-watermarks-from-ai-content/)  
21. OpenAI Sora Video Watermark Removers Push Real AI Slop, 访问时间为 2025-11-10， [https://www.aiornot.com/blog/openai-sora-video-watermark-removers-push-real-ai-slop](https://www.aiornot.com/blog/openai-sora-video-watermark-removers-push-real-ai-slop)  
22. OpenAI's Sora: When Seeing Should Not Be Believing - NewsGuard, 访问时间为 2025-11-10， [https://www.newsguardtech.com/special-reports/openai-sora-seeing-should-not-be-believing/](https://www.newsguardtech.com/special-reports/openai-sora-seeing-should-not-be-believing/)  
23. OpenAI’s Sora 2 Found To Generate False Claim Videos 80% of the Time, 访问时间为 2025-11-10， [https://www.technewsworld.com/story/openais-sora-2-found-to-generate-false-claim-videos-80-of-the-time-179973.html](https://www.technewsworld.com/story/openais-sora-2-found-to-generate-false-claim-videos-80-of-the-time-179973.html)  
24. How is AI changing the content creator economy in 2025? - Torres Marketing, 访问时间为 2025-11-10， [https://www.torresmarketinginc.com/blog/how-is-ai-changing-the-content-creator-economy-in-2025](https://www.torresmarketinginc.com/blog/how-is-ai-changing-the-content-creator-economy-in-2025)  
25. AI-Powered Creator Economy: The 2025 Revolution - Digicrusader, 访问时间为 2025-11-10， [https://digicrusader.com/the-creator-economy-in-2025-how-ai-is-empowering-content-creators/](https://digicrusader.com/the-creator-economy-in-2025-how-ai-is-empowering-content-creators/)  
26. AI & Robotics | Tesla, 访问时间为 2025-11-10， [https://www.tesla.com/AI](https://www.tesla.com/AI)  
27. Tesla Optimus Robot Advances AI for Manufacturing and Beyond, 访问时间为 2025-11-10， [https://www.webpronews.com/tesla-optimus-robot-advances-ai-for-manufacturing-and-beyond/](https://www.webpronews.com/tesla-optimus-robot-advances-ai-for-manufacturing-and-beyond/)  
28. Tesla Progress in Robotics and Future Plans, 访问时间为 2025-11-10， [https://www.teslaacessories.com/blogs/news/tesla-progress-in-robotics-and-future-plans](https://www.teslaacessories.com/blogs/news/tesla-progress-in-robotics-and-future-plans)  
29. Optimus at the Core: Tesla's Vision for Robots in Industry - Rockingrobots, 访问时间为 2025-11-10， [https://www.rockingrobots.com/optimus-at-the-core-teslas-vision-for-robots-in-industry/](https://www.rockingrobots.com/optimus-at-the-core-teslas-vision-for-robots-in-industry/)  
30. Humanoid robots 2025: the race to useful intelligence - Yole Group, 访问时间为 2025-11-10， [https://www.yolegroup.com/press-release/humanoid-robots-2025-the-race-to-useful-intelligence/](https://www.yolegroup.com/press-release/humanoid-robots-2025-the-race-to-useful-intelligence/)  
31. Elon Musk predicts a future where 'Optimus would be an incredible surgeon' and no one lives in poverty | - The Times of India, 访问时间为 2025-11-10， [https://timesofindia.indiatimes.com/technology/tech-news/elon-musk-predicts-a-future-where-optimus-would-be-an-incredible-surgeon-and-no-one-lives-in-poverty/articleshow/124899766.cms](https://timesofindia.indiatimes.com/technology/tech-news/elon-musk-predicts-a-future-where-optimus-would-be-an-incredible-surgeon-and-no-one-lives-in-poverty/articleshow/124899766.cms)  
32. arxiv.org, 访问时间为 2025-11-10， [https://arxiv.org/html/2509.00117](https://arxiv.org/html/2509.00117)  
33. Embodied AI: Emerging Risks and Opportunities for Policy Action - ResearchGate, 访问时间为 2025-11-10， [https://www.researchgate.net/publication/395214410\_Embodied\_AI\_Emerging\_Risks\_and\_Opportunities\_for\_Policy\_Action](https://www.researchgate.net/publication/395214410_Embodied_AI_Emerging_Risks_and_Opportunities_for_Policy_Action)  
34. Towards Safe and Trustworthy Embodied AI: Foundations, Status, and Prospects - OpenReview, 访问时间为 2025-11-10， [https://openreview.net/pdf/a3b0eb5349f3c0dd92e21b43b04037add70c669a.pdf](https://openreview.net/pdf/a3b0eb5349f3c0dd92e21b43b04037add70c669a.pdf)  
35. Emerging Risks from Embodied AI Require Urgent Policy Action - OpenReview, 访问时间为 2025-11-10， [https://openreview.net/pdf/7ff6b98416867df116004ee51bc7833e1b85c2c9.pdf](https://openreview.net/pdf/7ff6b98416867df116004ee51bc7833e1b85c2c9.pdf)  
36. Evolving descriptive text of mental content from human brain activity (Nov 2025\) - YouTube, 访问时间为 2025-11-10， [https://www.youtube.com/watch?v=MiPtJcuVfbw](https://www.youtube.com/watch?v=MiPtJcuVfbw)  
37. Fully Autonomous AI Agents Should Not be Developed - arXiv, 访问时间为 2025-11-10， [https://arxiv.org/html/2502.02649v3](https://arxiv.org/html/2502.02649v3)  
38. \[2502.02649\] Fully Autonomous AI Agents Should Not be Developed - arXiv, 访问时间为 2025-11-10， [https://arxiv.org/abs/2502.02649](https://arxiv.org/abs/2502.02649)  
39. AI can now describe what you are thinking: Scientists unveil 'mind ..., 访问时间为 2025-11-10， [https://m.economictimes.com/magazines/panache/ai-can-now-describe-what-you-are-thinking-scientists-unveil-mind-captioning-breakthrough-that-turns-thoughts-into-words/amp\_articleshow/125187118.cms](https://m.economictimes.com/magazines/panache/ai-can-now-describe-what-you-are-thinking-scientists-unveil-mind-captioning-breakthrough-that-turns-thoughts-into-words/amp_articleshow/125187118.cms)  
40. 'Mind-captioning' AI decodes brain activity to turn thoughts into text - PubMed, 访问时间为 2025-11-10， [https://pubmed.ncbi.nlm.nih.gov/41198973/](https://pubmed.ncbi.nlm.nih.gov/41198973/)  
41. AI can now describe what you are thinking: Scientists unveil ‘mind captioning’ breakthrough that turns thoughts into words, 访问时间为 2025-11-10， [https://m.economictimes.com/magazines/panache/ai-can-now-describe-what-you-are-thinking-scientists-unveil-mind-captioning-breakthrough-that-turns-thoughts-into-words/articleshow/125187118.cms](https://m.economictimes.com/magazines/panache/ai-can-now-describe-what-you-are-thinking-scientists-unveil-mind-captioning-breakthrough-that-turns-thoughts-into-words/articleshow/125187118.cms)  
42. Brain Decoder Translates Visual Thoughts Into Text, 访问时间为 2025-11-10， [https://neurosciencenews.com/brain-decoder-translates-visual-thoughts-into-text/](https://neurosciencenews.com/brain-decoder-translates-visual-thoughts-into-text/)  
43. navigating risks, rights and regulation: Advances in neuroscience challenge contemporary legal frameworks to protect mental privacy, 访问时间为 2025-11-10， [https://www.embopress.org/doi/10.1038/s44319-025-00505-6](https://www.embopress.org/doi/10.1038/s44319-025-00505-6)  
44. Brain-Computer Interfaces: Privacy and Ethical Considerations for the Connected Mind, 访问时间为 2025-11-10， [https://fpf.org/blog/brain-computer-interfaces-privacy-and-ethical-considerations-for-the-connected-mind/](https://fpf.org/blog/brain-computer-interfaces-privacy-and-ethical-considerations-for-the-connected-mind/)  
45. AI Turns Brain Scans Into Full Sentences and It’s Eerie To Say The Least, 访问时间为 2025-11-10， [https://www.zmescience.com/future/ai-turns-brain-scans-into-full-sentences-and-its-eerie-to-say-the-least/](https://www.zmescience.com/future/ai-turns-brain-scans-into-full-sentences-and-its-eerie-to-say-the-least/)  
46. Does brain-computer interface-based mind reading threaten mental privacy? ethical reflections from interviews with Chinese experts - PubMed Central, 访问时间为 2025-11-10， [https://pmc.ncbi.nlm.nih.gov/articles/PMC12522429/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12522429/)  
47. Mind-Reading Technology and Privacy Concerns | by Roshni Chandnani | Medium, 访问时间为 2025-11-10， [https://medium.com/@roshni.chandnani01/mind-reading-technology-and-privacy-concerns-b71ecd9d2ba3](https://medium.com/@roshni.chandnani01/mind-reading-technology-and-privacy-concerns-b71ecd9d2ba3)  
48. \[2511.02824\] Kosmos: An AI Scientist for Autonomous Discovery - arXiv, 访问时间为 2025-11-10， [https://arxiv.org/abs/2511.02824](https://arxiv.org/abs/2511.02824)  
49. Kosmos: An AI Scientist for Autonomous Discovery (2511.02824v1) - Emergent Mind, 访问时间为 2025-11-10， [https://www.emergentmind.com/papers/2511.02824](https://www.emergentmind.com/papers/2511.02824)  
50. (PDF) Kosmos: An AI Scientist for Autonomous Discovery - ResearchGate, 访问时间为 2025-11-10， [https://www.researchgate.net/publication/397280257\_Kosmos\_An\_AI\_Scientist\_for\_Autonomous\_Discovery](https://www.researchgate.net/publication/397280257_Kosmos_An_AI_Scientist_for_Autonomous_Discovery)  
51. Meet Kosmos: An AI Scientist that Automates Data-Driven Discovery - MarkTechPost, 访问时间为 2025-11-10， [https://www.marktechpost.com/2025/11/09/meet-kosmos-an-ai-scientist-that-automates-data-driven-discovery/](https://www.marktechpost.com/2025/11/09/meet-kosmos-an-ai-scientist-that-automates-data-driven-discovery/)  
52. My Hands-On Review of Kimi K2 Thinking: The Open-Source AI That's Changing the Game : r/LocalLLaMA - Reddit, 访问时间为 2025-11-10， [https://www.reddit.com/r/LocalLLaMA/comments/1oqi4qp/my\_handson\_review\_of\_kimi\_k2\_thinking\_the/](https://www.reddit.com/r/LocalLLaMA/comments/1oqi4qp/my_handson_review_of_kimi_k2_thinking_the/)  
53. Introducing Kimi K2 Thinking - Moonshot, 访问时间为 2025-11-10， [https://moonshotai.github.io/Kimi-K2/thinking.html](https://moonshotai.github.io/Kimi-K2/thinking.html)  
54. AI race heats up as Chinese start-up Moonshot launches Kimi K2 Thinking, 访问时间为 2025-11-10， [https://www.siliconrepublic.com/machines/ai-race-chinese-start-up-moonshot-launches-kimi-k2-thinking](https://www.siliconrepublic.com/machines/ai-race-chinese-start-up-moonshot-launches-kimi-k2-thinking)  
55. Kimi K2 Thinking - Simon Willison's Weblog, 访问时间为 2025-11-10， [https://simonwillison.net/2025/Nov/6/kimi-k2-thinking/](https://simonwillison.net/2025/Nov/6/kimi-k2-thinking/)  
56. A new Chinese AI model claims to outperform GPT-5 and Sonnet 4.5 - and it's free, 访问时间为 2025-11-10， [https://www.zdnet.com/article/a-new-chinese-ai-model-claims-to-outperform-gpt-5-and-sonnet-4-5-and-its-free/](https://www.zdnet.com/article/a-new-chinese-ai-model-claims-to-outperform-gpt-5-and-sonnet-4-5-and-its-free/)  
57. Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents - arXiv, 访问时间为 2025-11-10， [https://arxiv.org/html/2510.24383v1](https://arxiv.org/html/2510.24383v1)  
58. \[2510.24383\] Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents - arXiv, 访问时间为 2025-11-10， [https://arxiv.org/abs/2510.24383](https://arxiv.org/abs/2510.24383)  
59. Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents - ChatPaper, 访问时间为 2025-11-10， [https://chatpaper.com/zh-CN/chatpaper/paper/204370](https://chatpaper.com/zh-CN/chatpaper/paper/204370)  
60. Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents - ChatPaper, 访问时间为 2025-11-10， [https://chatpaper.com/paper/204370](https://chatpaper.com/paper/204370)  
61. Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents - arXiv, 访问时间为 2025-11-10， [https://arxiv.org/pdf/2510.24383](https://arxiv.org/pdf/2510.24383)  
62. Commonwealth Fusion Systems partners with Google DeepMind -- ANS / Nuclear Newswire, 访问时间为 2025-11-10， [https://www.ans.org/news/2025-10-22/article-7484/commonwealth-fusion-systems-partners-with-google-deepmind/](https://www.ans.org/news/2025-10-22/article-7484/commonwealth-fusion-systems-partners-with-google-deepmind/)  
63. With AI alliance, Google DeepMind and CFS take fusion to the next level, 访问时间为 2025-11-10， [https://blog.cfs.energy/with-ai-alliance-google-deepmind-and-cfs-take-fusion-to-the-next-level/](https://blog.cfs.energy/with-ai-alliance-google-deepmind-and-cfs-take-fusion-to-the-next-level/)  
64. Google DeepMind is bringing AI to the next generation of fusion ..., 访问时间为 2025-11-10， [https://deepmind.google/blog/bringing-ai-to-the-next-generation-of-fusion-energy/](https://deepmind.google/blog/bringing-ai-to-the-next-generation-of-fusion-energy/)  
65. AI for Nature. How AI can democratize and scale action on nature - Google Sustainability, 访问时间为 2025-11-10， [https://sustainability.google/reports/google-2025-AI-for-Nature/](https://sustainability.google/reports/google-2025-AI-for-Nature/)  
66. Three ways Google scientists use AI to better understand nature ..., 访问时间为 2025-11-10， [https://deepmind.google/blog/mapping-modeling-and-understanding-nature-with-ai/](https://deepmind.google/blog/mapping-modeling-and-understanding-nature-with-ai/)  
67. News - Google DeepMind, 访问时间为 2025-11-10， [https://deepmind.google/blog/](https://deepmind.google/blog/)  
68. Forecasting the future of forests with AI: From counting losses to predicting risk, 访问时间为 2025-11-10， [https://research.google/blog/forecasting-the-future-of-forests-with-ai-from-counting-losses-to-predicting-risk/](https://research.google/blog/forecasting-the-future-of-forests-with-ai-from-counting-losses-to-predicting-risk/)  
69. How Google's AI is Listening to Nature & Mapping the Planet's Health - Times Of AI, 访问时间为 2025-11-10， [https://www.timesofai.com/news/how-googles-ai-is-listening-to-nature-mapping-the-planets-health/](https://www.timesofai.com/news/how-googles-ai-is-listening-to-nature-mapping-the-planets-health/)  
70. AI in life sciences helps us reimagine the future of health | World ..., 访问时间为 2025-11-10， [https://www.weforum.org/stories/2025/10/life-sciences-generative-ai-future-human-health/](https://www.weforum.org/stories/2025/10/life-sciences-generative-ai-future-human-health/)  
71. The Future of AI-Enabled Health: Leading the Way - World Economic Forum: Publications, 访问时间为 2025-11-10， [https://reports.weforum.org/docs/WEF\_The\_Future\_of\_AI\_Enabled\_Health\_2025.pdf](https://reports.weforum.org/docs/WEF_The_Future_of_AI_Enabled_Health_2025.pdf)  
72. 2025 World Internet Conference Wuzhen Summit opens in east China, 访问时间为 2025-11-10， [https://en.qstheory.cn/2025-11/08/c\_1138901.htm](https://en.qstheory.cn/2025-11/08/c_1138901.htm)  
73. Chinese tech firms unveil AI-powered innovations blending with real ..., 访问时间为 2025-11-10， [https://www.globaltimes.cn/page/202511/1347634.shtml](https://www.globaltimes.cn/page/202511/1347634.shtml)  
74. Wuzhen 2025: Global Tech Leaders Weigh In on China's AI - Complete AI Training, 访问时间为 2025-11-10， [https://completeaitraining.com/news/wuzhen-2025-global-tech-leaders-weigh-in-on-chinas-ai/](https://completeaitraining.com/news/wuzhen-2025-global-tech-leaders-weigh-in-on-chinas-ai/)  
75. World Internet Conference, 访问时间为 2025-11-10， [https://www.wicinternet.org/](https://www.wicinternet.org/)  
76. 2025 World Internet Conference Wuzhen Summit concludes, with Chinese firms' Embodied AI taking center stage - Global Times, 访问时间为 2025-11-10， [https://www.globaltimes.cn/page/202511/1347771.shtml](https://www.globaltimes.cn/page/202511/1347771.shtml)